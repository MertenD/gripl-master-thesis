@ONLINE{omgbpmn,
  author = {OMG},
  title = {Business Process Model and Notation (BPMN)},
  version = {2.0.2},
  year = {2013},
  month = {12},
  url = {https://www.omg.org/spec/BPMN/2.0.2/PDF},
  urldate = {2025-06-03}
}

@ONLINE{omgbpmn-xsd,
  author = {OMG},
  title = {About the Business Process Model And Notation Specification Version 2.0},
  url = {https://www.omg.org/spec/BPMN/2.0/About-BPMN},
  year = {2011},
  urldate = {2025-06-03}
}

@misc{GDPR2016,
  title = {Verordnung (EU) 2016/679 des Europäischen Parlaments und des Rates vom 27. April 2016 zum Schutz natürlicher Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr und zur Aufhebung der Richtlinie 95/46/EG (Datenschutz-Grundverordnung)},
  author = {{Europäische Union}},
  year = {2016},
  howpublished = {\url{https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32016R0679}},
}

@inproceedings{Capodieci2023BPMNEnabledDP,
  title={BPMN-Enabled Data Protection and GDPR Compliance},
  author={Antonio Capodieci and Mimma De Carolis and Stefano Lisi and Luca Mainetti and Roberto Paiano and Mariavittoria Ugirashebuja},
  booktitle={IS-EUD Workshops},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259099646},
  abstract = {The European Parliament adopted the European General Data Protection Regulation (GDPR, EU 2016/679) which revolutionized the legislative framework for personal data protection within the European Union. The GDPR mandates organizations to shift from a passive approach, relying on minimum security measures outlined in the 1994 EU Directive, to a proactive accountability-based approach. Organizations are expected to implement verification systems, foster continuous improvement, and follow principles such as privacy by design and privacy by default. The latter principle emphasizes incorporating privacy considerations throughout the entire engineering process. The challenge for organizations lies in effectively auditing their compliance with the GDPR. This study proposes a structured approach based on business process modeling to aid in GDPR compliance. It involves identifying crucial compliance points for the GDPR. A case study is presented where the method is applied to a purchase of a health insurance policy process in the context of the Secure Safe Apulia project.},
}

@article{nake2023towards,
  title={Towards identifying gdpr-critical tasks in textual business process descriptions},
  author={Nake, Leonard and Kuehnel, Stephan and Bauer, Laura and Sackmann, Stefan},
  year={2023},
  publisher={Gesellschaft f{\"u}r Informatik eV},
  url = {https://dl.gi.de/server/api/core/bitstreams/84ac5110-1a0f-4e3c-bdf8-6393555a7212/content},
  abstract = {Complying with data protection regulations is an essential duty for organizations since violating them would lead to monetary penalties from authorities. In Europe, the General Data Protection Regulation (GDPR) defines personal data and requirements for dealing with this type of data. Hence, organizations must identify business activities that deal with personal data to establish measures to fulfill these requirements. Especially for large organizations, a manual identification can be labor-intensive and error-prone. However, textual business process descriptions, such as work instructions, provide valuable insights into the data used in organizations. Therefore, we propose a first approach to automatically identify GDPR-critical tasks in textual business process descriptions. More specifically, we use a supervised machine learning algorithm to automatically identify whether a task deals with personal data or not. A first evaluation of our approach with a dataset of 37 process descriptions containing 509 activities demonstrates that our approach generates satisfactory results.},
}

@article{varela2025business,
  title={Business process models and simulation to enable GDPR compliance},
  author={Varela-Vaca, {\'A}ngel Jes{\'u}s and G{\'o}mez-L{\'o}pez, Mar{\'\i}a Teresa and Morales Zamora, Yolanda and M. Gasca, Rafael},
  journal={International Journal of Information Security},
  volume={24},
  number={1},
  pages={41},
  year={2025},
  publisher={Springer},
  url = {https://link.springer.com/article/10.1007/s10207-024-00952-7},
  abstract = {The general data protection regulation (GDPR) provides European individuals with a regulatory framework for personal data protection and privacy. Compliance with this regulation represents an essential challenge for organisations that store, transmit, and process personal data. Millionaire fines are imposed by European protection authorities due to non-compliance. Currently, non-automated solutions are applied in organisations to carry out regulatory compliance, and therefore expensive manual implementation and audits are necessary to ensure GDPR compliance. To avoid these drawbacks, this paper presents a data model and a business process model as a first step towards designing automated mechanisms for implementing the GDPR. Furthermore, the proposed models are employed to support business process simulation (BPS), which includes aspects of performance, cost, and scalability, for evaluating the resource human impact and the execution time that our proposal can have in organisations. These factors would facilitate informed decision-making by the data controller regarding the resources and the degree of GDPR compliance, supporting data controller decisions regarding determining the necessary types of resources to achieve a suitable level of compliance and to obtain the degree of GDPR compliance. Given the large number of legal articles on the GDPR and owing to space limitation herein, we focus on Articles 33 and 34 regarding notification and communication of a personal data breach.},
}

@article{ciaramella2022leveraging,
  title={Leveraging Pre-trained LLMs for GDPR Compliance in Online Privacy Policies},
  author={Ciaramella, Giovanni and Petrillo, Luca and Varilek, Margaret and Mercaldo, Francesco and Comand{\'e}, Giovanni and Martinelli, Fabio},
  year={2022},
  url = {https://ceur-ws.org/Vol-3962/paper44.pdf},
  abstract = {This article explores the use of Large Language Models (LLMs) to determine if online privacy policies comply with the General Data Protection Regulation (GDPR) since privacy policies do not always adhere to all relevant GDPR requirements. This paper proposes a method to classify privacy policies as compliant or not with a single duty within Article 13 (2)(b) of the GDPR, which mandates that data subjects be informed of their right to rectification or erasure of personal data. To address that, we employed several LLMs such as BERT-base-uncased, roBERTa-base, distilBERT-base-uncased, t5-base, and ERNIE-2.0-base-en on a dataset built by the authors from European websites domains. Moreover, once the dataset was built, a legal expert from our research team manually classified a set of privacy policies to perform the contextual sentence similarity task. As the final step, we employed a set of unseen privacy policies to test models, obtaining interesting results demonstrating moderate accuracy in identifying compliant phrases using these thresholds. Future research could include expanding the analysis to encompass other GDPR requirements and refining the models.},
}

@inproceedings{pragyan2024toward,
  title={Toward Regulatory Compliance: A few-shot Learning Approach to Extract Processing Activities},
  author={Pragyan, KC and Ghandiparsi, Rambod and Slavin, Rocky and Ghanavati, Sepideh and Breaux, Travis and Hosseini, Mitra Bokaei},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW)},
  pages={241--250},
  year={2024},
  organization={IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/10628578},
  abstract = {The widespread use of mobile applications has driven the growth of the industry, with companies relying heavily on user data for services like targeted advertising and personalized offerings. In this context, privacy regulations such as the General Data Protection Regulation (GDPR) playa crucial role. One of the GDPR requirements is the maintenance of a Record of Processing Activities (RoPA) by companies. RoPA encompasses various details, including the description of data processing activities, their purposes, types of data involved, and other relevant external entities. Small app-developing companies face challenges in meeting such compliance requirements due to resource limitations and tight timelines. To aid these developers and prevent fines, we propose a method to generate segments of RoPA from user-authored usage scenarios using large language models (LLMs). Our method employs few-shot learning with G PT-3.S Turbo to summarize usage scenarios and generate RoPA segments. We evaluate different factors that can affect few-shot learning performance consistency for our summarization task, including the number of examples in few-shot learning prompts, repetition, and order permutation of examples in the prompts. Our findings highlight the significant influence of the number of examples in prompts on summarization F1 scores, while demonstrating negligible variability in F1 scores across multiple prompt repetitions. Our prompts achieve successful summarization of processing activities with an average 70 \% ROUGE-L F1 score. Finally, we discuss avenues for improving results through manual evaluation of the generated summaries.},
}

@online{mistralai,
  author  = {Mistral AI},
  title   = {Mistral AI},
  year    = {2025},
  url     = {https://mistral.ai/},
  urldate = {2025-09-21},
}

@article{schwerin2024systematic,
  title={A systematic comparison between open-and closed-source large language models in the context of generating gdpr-compliant data categories for processing activity records},
  author={von Schwerin, Magdalena and Reichert, Manfred},
  journal={Future Internet},
  volume={16},
  number={12},
  pages={459},
  year={2024},
  publisher={MDPI},
  url = {https://www.mdpi.com/1999-5903/16/12/459},
  abstract = {This study investigates the capabilities of open-source Large Language Models (LLMs) in automating GDPR compliance documentation, specifically in generating data categories—types of personal data (e.g., names, email addresses)—for processing activity records, a document required by the General Data Protection Regulation (GDPR). By comparing four state-of-the-art open-source models with the closed-source GPT-4, we evaluate their performance using benchmarks tailored to GDPR tasks: a multiple-choice benchmark testing contextual knowledge (evaluated by accuracy and F1 score) and a generation benchmark evaluating structured data generation. In addition, we conduct four experiments using context-augmenting techniques such as few-shot prompting and Retrieval-Augmented Generation (RAG). We evaluate these on performance metrics such as latency, structure, grammar, validity, and contextual understanding. Our results show that open-source models, particularly Qwen2-7B, achieve performance comparable to GPT-4, demonstrating their potential as cost-effective and privacy-preserving alternatives. Context-augmenting techniques show mixed results, with RAG improving performance for known categories but struggling with categories not contained in the knowledge base. Open-source models excel at structured legal tasks, although challenges remain in handling ambiguous legal language and unstructured scenarios. These findings underscore the viability of open-source models for GDPR compliance, while highlighting the need for fine-tuning and improved context augmentation to address complex use cases.},
}

@inproceedings{schneid2021uncovering,
  title={Uncovering data-flow anomalies in BPMN-based pro- cess-driven applications},
  author={Schneid, Konrad and Kuchen, Herbert and Th{\"o}ne, Sebastian and Di Bernardo, Sascha},
  booktitle={Proceedings of the 36th Annual ACM Symposium on Applied Computing},
  pages={1504--1512},
  year={2021},
  url={https://dl.acm.org/doi/abs/10.1145/3412841.3442025},
  abstract = {Process-Driven Applications flourish through the interaction between an executable BPMN process model, human tasks, and external software services. All these components operate on shared process data, so it is even more important to check the correct data flow. However, data flow is in most cases not explicitly defined but hidden in model elements, form declarations, and program code. This paper elaborates on data-flow anomalies acting as indicators for potential errors and how such anomalies can be uncovered despite implicit and hidden data-flow definitions. By considering an integrated view, it goes beyond other approaches which are restricted to separate data-flow analysis of either process model or source code. The main idea is to merge call graphs representing programmed services into a control-flow representation of the process model, to label the resulting graph with associated data operations, and to detect anomalies in that labeled graph using a dedicated data-flow analysis. The applicability of the solution is demonstrated by a prototype designed for the Camunda BPM platform.},
}

@online{camunda,
  author = {Camunda Services GmbH},
  title = {Camunda Platform},
  year = {2025},
  url = {https://camunda.com/de/},
  urldate = {2025-09-22},
}

@online{bpmnio,
  author = {Camunda Services GmbH},
  title = {BPMN.io - Web-based tooling for BPMN, DMN and Forms},
  year = {2025},
  url = {https://bpmn.io/},
  urldate = {2025-09-22},
}

@misc{gdpr-guidelines-2019,
  author={{European Data Protection Board}},
  title={Guidelines 4/2019 on Article 25 Data Protection by Design and by Default},
  version = {2.0},
  year={2020},
  month = {10},
  day = {20},
  howpublished={\url{https://www.edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_201904_dataprotection_by_design_and_by_default_v2.0_en.pdf}},
}

@misc{rdg-2007,
  author={{Bundesministerium der Justiz}},
  title={Gesetz über außergerichtliche Rechtsdienstleistungen (Rechtsdienstleistungsgesetz - RDG)},
  year={2007},
  month={12},
  day={12},
  howpublished={\url{https://www.gesetze-im-internet.de/rdg/}},
  urldate={2025-08-15},
}

@online{ibm-gpt,
  title={Was ist ein GPT (Generative Pre-Trained Transformer)?},
  author={Belcic, Ivan and Stryker, Cole},
  year={2024},
  month={09},
  day={18},
  urldate={2025-09-18},
  url={https://www.ibm.com/de-de/think/topics/gpt}
}

@online{openai-models,
  author = {OpenAI},
  title = {Model Overview},
  year = {2025},
  url = {https://platform.openai.com/docs/models},
  urldate = {2025-09-18}
}

@article{vaswani2017attention,
  author={Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title={Attention Is All You Need},
  journal={CoRR},
  volume= {abs/1706.03762},
  year= {2017},
  url= {http://arxiv.org/abs/1706.03762},
  eprinttype= {arXiv},
  eprint= {1706.03762},
  timestamp= {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl= {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource= {dblp computer science bibliography, https://dblp.org},
  abstract={The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks that include an encoder and a decoder. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer,
based solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to
be superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-
to-German translation task, improving over the existing best results, including
ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,
our model establishes a new single-model state-of-the-art BLEU score of 41.8 after
training for 3.5 days on eight GPUs, a small fraction of the training costs of the
best models from the literature. We show that the Transformer generalizes well to
other tasks by applying it successfully to English constituency parsing both with
large and limited training data.},
}

@misc{minaee2025largelanguagemodelssurvey,
  title={Large Language Models: A Survey},
  author={Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
  year={2025},
  eprint={2402.06196},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.06196},
  abstract={Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022. LLMs' ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by scaling laws \cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performance of several popular LLMs on a set of representative benchmarks. Finally, we conclude the paper by discussing open challenges and future research directions. },
}

@article{liu2023prompting,
  author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  year = {2023},
  issue_date = {September 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {55},
  number = {9},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3560815},
  doi = {10.1145/3560815},
  abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website  including constantly updated survey and paperlist.},
  journal = {ACM Comput. Surv.},
  month = jan,
  articleno = {195},
  numpages = {35},
  keywords = {Pre-trained language models, prompting}
}

@inproceedings{brown2020fewshot,
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title = {Language Models are Few-Shot Learners},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  volume = {33},
  year = {2020},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic,
few-shot performance, sometimes even becoming competitive with prior state-of-
the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive
language model with 175 billion parameters, 10x more than any previous non-
sparse language model, and test its performance in the few-shot setting. For all
tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks
and few-shot demonstrations specified purely via text interaction with the model.
GPT-3 achieves strong performance on many NLP datasets, including translation,
question-answering, and cloze tasks. We also identify some datasets where GPT-
3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces
methodological issues related to training on large web corpora.},
}

@misc{openai_function_calling_2023,
  title        = {Function calling and other API updates},
  author       = {{OpenAI}},
  howpublished = {\url{https://openai.com/index/function-calling-and-other-api-updates/}},
  year         = {2023},
  urldate         = {2025-07-10}
}

@online{mistralai_structured_output,
  author  = {Mistral AI},
  title   = {Mistral AI - Structured Output},
  year    = {2025},
  url     = {https://docs.mistral.ai/capabilities/structured-output/structured_output_overview/},
  urldate = {2025-07-11}
}

@online{openai_structured_output,
  author  = {OpenAI},
  title   = {OpenAI - Structured model outputs},
  url     = {https://docs.mistral.ai/capabilities/structured-output/structured_output_overview/},
  urldate = {2025-07-11}
}

@online{openai-hello-gpt-4o,
  author  = {OpenAI},
  title   = {Hello GPT-4o},
  year    = {2024},
  month = {5},
  day = {13},
  url     = {https://openai.com/index/hello-gpt-4o/},
  urldate = {2025-07-21}
}

@article{scholak2021picard,
  author       = {Torsten Scholak and
                  Nathan Schucher and
                  Dzmitry Bahdanau},
  title        = {{PICARD:} Parsing Incrementally for Constrained Auto-Regressive Decoding
                  from Language Models},
  journal      = {CoRR},
  volume       = {abs/2109.05093},
  year         = {2021},
  url          = {https://arxiv.org/abs/2109.05093},
  eprinttype    = {arXiv},
  eprint       = {2109.05093},
  timestamp    = {Tue, 21 Sep 2021 17:46:04 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2109-05093.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code and trained models available at this https URL), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions. },
}

@misc{kalai2025languagemodelshallucinate,
  title={Why Language Models Hallucinate},
  author={Adam Tauman Kalai and Ofir Nachum and Santosh S. Vempala and Edwin Zhang},
  year={2025},
  eprint={2509.04664},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2509.04664},
  abstract = {Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such "hallucinations" persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious -- they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded -- language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This "epidemic" of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems. },
}

@article{ji2023hallucinationsurvey,
  author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  title = {Survey of Hallucination in Natural Language Generation},
  year = {2023},
  issue_date = {December 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {55},
  number = {12},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3571730},
  doi = {10.1145/3571730},
  abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
  journal = {ACM Comput. Surv.},
  month = mar,
  articleno = {248},
  numpages = {38},
  keywords = {consistency in NLG, factuality in NLG, faithfulness in NLG, extrinsic hallucination, intrinsic hallucination, Hallucination}
}

@online{deepseek,
  author  = {DeepSeek AI},
  title   = {DeepSeek AI Open Source Hugging Face Models},
  year    = {2025},
  url     = {https://huggingface.co/deepseek-ai},
  urldate = {2025-07-17}
}

@online{qwen,
  author  = {Alibaba Qwen},
  title   = {Qwen Open Source Hugging Face Models},
  year    = {2025},
  url     = {https://huggingface.co/Qwen},
  urldate = {2025-07-17}
}

@misc{hooda2024policylr,
  title={PolicyLR: A Logic Representation For Privacy Policies},
  author={Ashish Hooda and Rishabh Khandelwal and Prasad Chalasani and Kassem Fawaz and Somesh Jha},
  year={2024},
  eprint={2408.14830},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2408.14830},
  abstract = {Privacy policies are crucial in the online ecosystem, defining how services handle user data and adhere to regulations such as GDPR and CCPA. However, their complexity and frequent updates often make them difficult for stakeholders to understand and analyze. Current automated analysis methods, which utilize natural language processing, have limitations. They typically focus on individual tasks and fail to capture the full context of the policies. We propose PolicyLR, a new paradigm that offers a comprehensive machine-readable representation of privacy policies, serving as an all-in-one solution for multiple downstream tasks. PolicyLR converts privacy policies into a machine-readable format using valuations of atomic formulae, allowing for formal definitions of tasks like compliance and consistency. We have developed a compiler that transforms unstructured policy text into this format using off-the-shelf Large Language Models (LLMs). This compiler breaks down the transformation task into a two-stage translation and entailment procedure. This procedure considers the full context of the privacy policy to infer a complex formula, where each formula consists of simpler atomic formulae. The advantage of this model is that PolicyLR is interpretable by design and grounded in segments of the privacy policy. We evaluated the compiler using ToS;DR, a community-annotated privacy policy entailment dataset. Utilizing open-source LLMs, our compiler achieves precision and recall values of 0.91 and 0.88, respectively. Finally, we demonstrate the utility of PolicyLR in three privacy tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison Shopping.},
}

@inproceedings{reimers2017reporting,
  title = {Reporting Score Distributions Makes a Difference: Performance Study of {LSTM}-networks for Sequence Tagging},
  author = {Reimers, Nils  and
      Gurevych, Iryna},
  editor = {Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month = {9},
  year = {2017},
  address = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/D17-1035/},
  doi = {10.18653/v1/D17-1035},
  pages = {338--348},
  abstract = {In this paper we show that reporting a single performance score is insufficient to compare non-deterministic approaches. We demonstrate for common sequence tagging tasks that the seed value for the random number generator can result in statistically significant ($p < 10^{-4}$) differences for state-of-the-art systems. For two recent systems for NER, we observe an absolute difference of one percentage point F₁-score depending on the selected seed value, making these systems perceived either as state-of-the-art or mediocre. Instead of publishing and reporting single performance scores, we propose to compare score distributions based on multiple executions. Based on the evaluation of 50.000 LSTM-networks for five sequence tagging tasks, we present network architectures that produce both superior performance as well as are more stable with respect to the remaining hyperparameters.}
}

@misc{camunda-bpmn-model-api,
  author       = {{Camunda Services GmbH}},
  title        = {BPMN Model API},
  year         = {2025},
  howpublished = {\url{https://docs.camunda.org/manual/latest/user-guide/model-api/bpmn-model-api/}},
  urldate = {2025-06-16},
}

@misc{camunda-bpmn-model-read,
  author       = {{Camunda Services GmbH}},
  title        = {BPMN Model API — Read a Model},
  year         = {2025},
  howpublished = {\url{https://docs.camunda.org/manual/latest/user-guide/model-api/bpmn-model-api/read-a-model/}},
  urldate = {2025-06-16}
}

@online{langchain4j-ai-services,
  author  = {{Quarkiverse Contributors}},
  title   = {AI Services Reference (Quarkus LangChain4j)},
  year    = {2025},
  url     = {https://docs.quarkiverse.io/quarkus-langchain4j/dev/ai-services.html},
  urldate = {2025-06-14}
}

@online{langchain4j,
  author  = {{Langchain4j}},
  title   = {LangChain4j Documentation 2025},
  year    = {2025},
  url     = {https://docs.langchain4j.dev/},
  urldate = {2025-06-14}
}

@online{langchain4j-chat-model,
    author  = {{Langchain4j}},
    title   = {Class OpenAiChatModel.OpenAiChatModelBuilder},
    year    = {2025},
    url     = {https://javadoc.io/doc/dev.langchain4j/langchain4j-open-ai/latest/dev/langchain4j/model/openai/OpenAiChatModel.OpenAiChatModelBuilder.html},
    urldate = {2025-06-14}
}

@online{bpmn-js,
  author  = {Camunda Services GmbH},
  title   = {bpmn-js - BPMN 2.0 viewer and editor.},
  year    = {2025},
  url     = {https://bpmn.io/toolkit/bpmn-js/},
  urldate = {2025-06-20}
}


@article{blake2025datasetdiversity,
  author = {Blake, Harrison and Esther, Dorcas},
  title = {Impact of Dataset Diversity on Model Evaluation Metrics},
  year = {2025},
  month = {01},
  url = {https://www.researchgate.net/publication/387898702_Impact_of_Dataset_Diversity_on_Model_Evaluation_Metrics},
  abstract = {The evaluation of machine learning models is a critical process in understanding their performance, reliability, and generalizability. Dataset diversity, encompassing factors such as data distribution, representation of minority groups, and feature variability, plays a vital role in determining the robustness and fairness of model evaluation metrics. This paper investigates the interplay between dataset diversity and evaluation metrics, exploring how variations in dataset characteristics can influence the interpretation of model performance. Through a combination of theoretical analysis and empirical experimentation, the study aims to uncover the complexities of dataset composition and its implications for machine learning development. The findings emphasize the importance of incorporating diverse datasets in model evaluation to ensure equitable, accurate, and meaningful outcomes.},
}

@online{edpb-meta-fine,
  author  = {European Data Protection Board (EDPB)},
  title   = {1.2 billion euro fine for Facebook as a result of EDPB binding decision},
  year    = {2023},
  month = {5},
  day = {22},
  url     = {https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en},
  urldate = {2025-10-02}
}

@online{reuters-amazon-fine,
  author  = {Reuters},
  title   = {Amazon hit with record EU data privacy fine},
  year    = {2021},
  month = {7},
  day = {30},
  url     = {https://www.reuters.com/business/retail-consumer/amazon-hit-with-886-million-eu-data-privacy-fine-2021-07-30/?utm_source=chatgpt.com},
  urldate = {2025-10-02}
}

@online{datenschutzticker-amazon-fine,
  author  = {Datenschutzticker},
  title   = {Gericht bestätigt Rekordbußgeld gegen Amazon},
  year    = {2025},
  month = {4},
  day = {2},
  url     = {https://datenschutzticker.de/2025/04/gericht-bestaetigt-rekordbussgeld-gegen-amazon/},
  urldate = {2025-10-02}
}

@article{sokolova2009measureclassification,
  title={A systematic analysis of performance measures for classification tasks},
  author={Sokolova, Marina and Lapalme, Guy},
  journal={Information processing \& management},
  volume={45},
  number={4},
  pages={427--437},
  year={2009},
  publisher={Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457309000259},
  abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies.},
}

@book{manning2008ir,
  author    = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Sch{\"u}tze},
  title     = {Introduction to Information Retrieval},
  year      = {2008},
  publisher = {Cambridge University Press},
  address   = {Cambridge},
  isbn      = {9780521865715},
  url       = {https://nlp.stanford.edu/IR-book/}
}

@online{ibm-llm-temperature,
  title={What is LLM Temperature?},
  author={Noble, Joshua},
  urldate={2025-10-3},
  url={https://www.ibm.com/think/topics/llm-temperature}
}

@misc{MRL_Research_License,
  title        = {Mistral AI Research License (MRL‑0.1)},
  author       = {{Mistral AI}},
  year         = {2024},
  url          = {https://mistral.ai/static/licenses/MRL-0.1.md},
  urldate      = {2025-10-05},
}

@misc{OSI_OSD,
  title        = {The Open Source Definition},
  author       = {{Open Source Initiative}},
  year         = {2006},
  url          = {https://opensource.org/osd},
  urldate      = {2025-10-05},
}

@misc{OpenAI_GPTOSS_Blog_2025,
  title        = {Introducing gpt-oss},
  author       = {{OpenAI}},
  year         = {2025},
  url          = {https://openai.com/index/introducing-gpt-oss/},
  urldate      = {2025-10-02},
}

@misc{OpenAI_GPTOSS_ModelCard_2025,
  title        = {gpt-oss-120b \& gpt-oss-20b Model Card},
  author       = {{OpenAI}},
  year         = {2025},
  url          = {https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf},
  urldate      = {2025-10-02},
}

@misc{Llama3_License,
  title        = {Meta Llama 3 Community License Agreement},
  author       = {{Meta}},
  year         = {2024},
  url          = {https://www.llama.com/llama3/license/},
  urldate      = {2025-09-30},
}

@misc{webdev-llm-sizes,
  title        = { Understand LLM sizes},
  author       = {Nalpas, Maud},
  year         = {2024},
  month = {5},
  day = {30},
  url          = {https://web.dev/articles/llm-sizes},
  urldate      = {2025-10-03},
}

@misc{ibm-llm-context,
  title        = {What is a context window?},
  author       = {Bergmann, Dave},
  url = {https://www.ibm.com/think/topics/context-window},
  year         = {2025},
  urldate      = {2025-10-03},
}

@misc{Mixtral_Blog,
  title        = {Mixtral of Experts: Mixtral 8x7B},
  author       = {{Mistral AI}},
  year         = {2023},
  url          = {https://mistral.ai/news/mixtral-of-experts},
  urldate      = {2025-10-01},
}

@misc{HF_Gemma3_12B_2025,
  title        = {google/gemma-3-12b-it — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/google/gemma-3-12b-it},
  urldate      = {2025-09-30},
}

@misc{HF_Gemma3_27B_2025,
  title        = {google/gemma-3-27b-it — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/google/gemma-3-27b-it},
  urldate      = {2025-09-30},
}

@misc{HF_Qwen7B_2025,
  title        = {unsloth/Qwen2.5-7B-Instruct},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/Qwen/Qwen2.5-7B-Instruct},
  urldate      = {2025-09-30},
}

@misc{HF_MistralLargeInstruct_2025,
  title        = {mistralai/Mistral-Large-Instruct-2411 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/mistralai/Mistral-Large-Instruct-2411},
  urldate      = {2025-09-30},
}

@misc{HF_Mistral7B_2025,
  title        = {mistralai/Mistral-7B-Instruct-v0.2 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3},
  urldate      = {2025-09-30},
}

@misc{HF_Mixtral8x7B_2025,
  title        = {mistralai/Mixtral-8x7B-Instruct-v0.1 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1},
  urldate      = {2025-09-30},
}

@misc{HF_DeepSeekR1_2025,
  title        = {deepseek-ai/DeepSeek-R1 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/deepseek-ai/DeepSeek-R1},
  urldate      = {2025-09-30},
}

@misc{Gemma3_License,
  title        = {Gemma 3 License Terms},
  author       = {{Google}},
  year         = {2025},
  month = {3},
  day = {24},
  url          = {https://ai.google.dev/gemma/terms},
  urldate      = {2025-09-30},
}

@misc{HF_Qwen3_235B_2025,
  title        = {Qwen3-235B-A22B-Thinking-2507 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507},
  urldate      = {2025-09-30},
}

@misc{HF_DeepSeek_V3_1_2025,
  title        = {deepseek-ai/DeepSeek-V3.1 — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/deepseek-ai/DeepSeek-V3.1},
  urldate      = {2025-09-30},
}

@misc{HF_DeepSeekR1_Distill_Qwen14B_2025,
  title        = {deepseek-ai/DeepSeek-R1-Distill-Qwen-14B — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B},
  urldate      = {2025-09-30},
}

@misc{mistral_models_overview,
    title        = {Models Overview},
    author       = {{Mistral AI}},
    year         = {2025},
    url          = {https://docs.mistral.ai/getting-started/models/models_overview/},
    urldate      = {2025-10-09},
}

@misc{openrouter,
    title        = {The Unified Interface For LLMs},
    author       = {{OpenRouter}},
    year         = {2025},
    url          = {https://openrouter.ai},
    urldate      = {2025-10-09},
}

@inproceedings{renze2024effect,
  title        = {The effect of sampling temperature on problem solving in large language models},
  author       = {Renze, Matthew and Guven, Erhan},
  booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages        = {7346--7356},
  year         = {2024},
  publisher    = {Association for Computational Linguistics},
  doi          = {10.48550/arXiv.2402.05201},
  archivePrefix= {arXiv},
  eprint       = {2402.05201}
}

@article{atil2024nondeterminism,
  title  = {Non-Determinism of Deterministic LLM Settings},
  author = {Atil, Berk and Aykent, Sarp and Chittams, Alexa and Fu, Lisheng and Passonneau, Rebecca J. and Radcliffe, Evan and Rajagopal, Guru Rajan and Sloan, Adam and Tudrej, Tomasz and Ture, Ferhan and Wu, Zhe and Xu, Lixinyu and Baldwin, Breck},
  journal= {arXiv preprint arXiv:2408.04667},
  year   = {2024},
  doi    = {10.48550/arXiv.2408.04667}
}

@inproceedings{mu2024navigating,
  title        = {Navigating prompt complexity for zero-shot classification: a study of large language models in computational social science},
  author       = {Mu, Yida and Wu, Ben P. and Thorne, William and Robinson, Ambrose and Aletras, Nikolaos and Scarton, Carolina and Bontcheva, Kalina and Song, Xingyi},
  booktitle    = {Proceedings of LREC-COLING 2024},
  year         = {2024},
  publisher    = {European Language Resources Association},
  doi          = {10.48550/arXiv.2305.14310},
  archivePrefix= {arXiv},
  eprint       = {2305.14310}
}

@misc{huggingface,
  title        = {Hugging Face - The AI community building the future.},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/},
  urldate      = {2025-10-09},
}

@online{mistral-data-storing,
  author  = {{Mistral AI}},
  title   = {Where do you store my data or my Organization's data?},
  year    = {2025},
  url     = {https://help.mistral.ai/en/articles/347629-where-do-you-store-my-data-or-my-organization-s-data},
  urldate = {2025-10-09}
}

@online{mistral-gdpr,
  author  = {{Mistral AI}},
  title   = {How can I exercise my GDPR rights?},
  year    = {2025},
  url     = {https://help.mistral.ai/en/articles/347639-how-can-i-exercise-my-gdpr-rights},
  urldate = {2025-10-09}
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
  year={2025},
  eprint={2501.12948},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2501.12948},
}

@online{HF_DeepSeekR1_Zero_2025,
  title        = {deepseek-ai/DeepSeek-R1-Zero — Model Card},
  author       = {{Hugging Face}},
  year         = {2025},
  url          = {https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero},
  urldate      = {2025-09-29},
}

@inbook{agostinelli2019achievingGDPRComliance,
  author  = {Agostinelli, Simone and Maggi, Fabrizio and Marrella, Andrea and Sapio, Francesco},
  year    = {2019},
  month   = {05},
  pages   = {10-22},
  title   = {Achieving {GDPR} Compliance of {BPMN} Process Models},
  isbn    = {978-3-030-21296-4},
  doi     = {10.1007/978-3-030-21297-1_2},
  url = {https://www.researchgate.net/publication/333312868_Achieving_GDPR_Compliance_of_BPMN_Process_Models},
  abstract= {In an increasingly digital world, where processing and exchange of personal data are key parts of everyday enterprise business processes (BPs), the right to data privacy is regulated and actively enforced in the European Union (EU) through the recently introduced General Data Protection Regulation (GDPR), whose aim is to protect EU citizens from privacy breaches. In this direction, GDPR is highly influencing the way organizations must approach data privacy, forcing them to rethink and upgrade their BPs in order to become GDPR compliant. For many organizations, this can be a daunting task, since little has been done so far to easily identify privacy issues in BPs. To tackle this challenge, in this paper, we provide an analysis of the main privacy constraints in GDPR and propose a set of design patterns to capturing and integrating such constraints in BP models. Using {BPMN} (Business Process Model and Notation) as modeling notation, our approach allows us to achieve full transparency of privacy constraints in BPs, making it possible to ensure their compliance with GDPR.}
}

@article{rodriguez2024largelanguagemodels,
  title   = {Large Language Models: A New Approach for Privacy Policy Analysis at Scale},
  author  = {Rodriguez, David and Yang, Ian and Del Alamo, Jose M. and Sadeh, Norman},
  journal = {Computing},
  volume  = {106},
  number  = {12},
  pages   = {3879--3903},
  year    = {2024},
  publisher = {Springer},
  doi     = {10.1007/s00607-024-01331-9},
  url     = {https://doi.org/10.1007/s00607-024-01331-9},
  abstract= {The number and dynamic nature of websites and mobile applications present regulators and app store operators with significant challenges when it comes to enforcing compliance with applicable privacy and data protection laws. Over the past several years, people have turned to Natural Language Processing (NLP) techniques to automate privacy compliance analysis (e.g., comparing statements in privacy policies with analysis of the code and behavior of mobile apps) and to answer people’s privacy questions. Traditionally, these NLP techniques have relied on labor-intensive and potentially error-prone manual annotation processes to build the corpora necessary to train them. This article explores and evaluates the use of Large Language Models (LLMs) as an alternative for effectively and efficiently identifying and categorizing a variety of data practice disclosures found in the text of privacy policies. Specifically, we report on the performance of ChatGPT and Llama 2, two particularly popular LLM-based tools. This includes engineering prompts and evaluating different configurations of these LLM techniques. Evaluation of the resulting techniques on well-known corpora of privacy policy annotations yields an F1 score exceeding 93\%. This score is higher than scores reported earlier in the literature on these benchmarks. This performance is obtained at minimal marginal cost (excluding the cost required to train the foundational models themselves). These results, which are consistent with those reported in other domains, suggest that LLMs offer a particularly promising approach to automated privacy policy analysis at scale.}
}

@inproceedings{silva2024entailment,
  author    = {Silva, Bhanuka and Denipitiyage, Dishanika and Seneviratne, Suranga and Mahanti, Anirban and Seneviratne, Aruna},
  booktitle = {2024 Conference on Building a Secure \& Empowered Cyberspace (BuildSEC)},
  title     = {Entailment-Driven Privacy Policy Classification with {LLMs}},
  year      = {2024},
  pages     = {8--15},
  keywords  = {Privacy; Data privacy; Annotations; Large language models; Cyberspace; Data collection; Large Language Models; Privacy Policies},
  doi       = {10.1109/BuildSEC64048.2024.00010},
  url = {https://ieeexplore.ieee.org/document/10874334},
  abstract  = {While many online services provide privacy policies for end users to read and understand what personal data are being collected, these documents are often lengthy and complicated. As a result, the vast majority of users do not read them at all, leading to data collection under uninformed consent. Several attempts have been made to make privacy policies more user-friendly by summarising them, providing automatic annotations or labels for key sections, or by offering chat interfaces to ask specific questions. With recent advances in Large Language Models (LLMs), there is an opportunity to develop more effective tools to parse privacy policies and help users make informed decisions. In this paper, we propose an entailment-driven LLM-based framework to classify paragraphs of privacy policies into meaningful labels that are easily understood by users. The results demonstrate that our framework outperforms traditional LLM methods, improving the F1 score on average by 11.2\%. Additionally, our framework provides inherently explainable and meaningful predictions.}
}

@misc{vidgof2023largelanguagemodelsbusiness,
  title        = {Large Language Models for Business Process Management: Opportunities and Challenges},
  author       = {Vidgof, Maxim and Bachhofner, Stefan and Mendling, Jan},
  year         = {2023},
  eprint       = {2304.04309},
  archivePrefix= {arXiv},
  primaryClass = {cs.SE},
  url          = {https://arxiv.org/abs/2304.04309},
  abstract     = {Large language models are deep learning models with a large number of parameters. The models made noticeable progress on a large number of tasks, allowing them to serve as valuable and versatile tools for a diverse range of applications. Their capabilities also offer opportunities for business process management; however, these opportunities have not yet been systematically investigated. In this paper, we address this research problem by foregrounding various management tasks of the {BPM} lifecycle and outlining six research directions.}
}

@article{kourani2025evaluating,
  title   = {Evaluating Large Language Models on Business Process Modeling: Framework, Benchmark, and Self-Improvement Analysis},
  author  = {Kourani, Humam and Berti, Alessandro and Schuster, Daniel and van der Aalst, Wil M. P.},
  journal = {Software and Systems Modeling},
  pages   = {1--36},
  year    = {2025},
  publisher = {Springer},
  url = {https://link.springer.com/article/10.1007/s10270-025-01318-w},
  abstract= {Large language models (LLMs) are rapidly transforming various fields, including business process management (BPM). This paper assesses the capabilities of LLMs on business process modeling using a framework for automating this task and a robust evaluation approach. We design a comprehensive benchmark consisting of 20 diverse business processes and assess 16 current state-of-the-art LLMs. Our analysis highlights significant performance variations across LLMs and reveals a positive correlation between efficient error handling and the quality of generated models. We also investigate self-improvement techniques (self-evaluation, input optimization, output optimization), finding output optimization particularly effective for lower-performing models.}
}

@article{bernardi2024conversing,
  title   = {Conversing with Business Process-Aware Large Language Models: The {BPLLM} Framework},
  author  = {Bernardi, Mario Luca and Casciani, Angelo and Cimitile, Marta and Marrella, Andrea},
  journal = {Journal of Intelligent Information Systems},
  volume  = {62},
  number  = {6},
  pages   = {1607--1629},
  year    = {2024},
  publisher = {Springer},
  url = {https://link.springer.com/article/10.1007/s10844-024-00898-1},
  abstract= {AI-Augmented Business Process Management Systems blend flexibility, autonomy, and conversational capability. Large Language Models (LLMs) boost such systems but empirical validations are scarce. We propose the Business Process Large Language Model (BPLLM) framework, coupling Retrieval-Augmented Generation with fine-tuning and process-aware chunking. Experiments show promising performance in identifying activities and sequence flows in process models, suggesting potential for process-aware DSSs.}
}

@misc{chatgpt,
  title        = {ChatGPT ist da},
  author       = {{OpenAI}},
  year         = {2022},
  month = {11},
  day = {30},
  url          = {https://openai.com/de-DE/index/chatgpt/},
  urldate      = {2025-10-19},
}

@misc{MMLU,
    title={Measuring Massive Multitask Language Understanding},
    author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
    year={2021},
    eprint={2009.03300},
    archivePrefix={arXiv},
    primaryClass={cs.CY},
    url={https://arxiv.org/abs/2009.03300},
}

@misc{MMLU-Pro,
    title={MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark},
    author={Yubo Wang and Xueguang Ma and Ge Zhang and Yuansheng Ni and Abhranil Chandra and Shiguang Guo and Weiming Ren and Aaran Arulraj and Xuan He and Ziyan Jiang and Tianle Li and Max Ku and Kai Wang and Alex Zhuang and Rongqi Fan and Xiang Yue and Wenhu Chen},
    year={2024},
    eprint={2406.01574},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2406.01574},
}

@misc{BBH,
    title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
    author={Mirac Suzgun and Nathan Scales and Nathanael Schaerli and Sebastian Gehrmann and Yi Tay and Hyung Won Chung and Aakanksha Chowdhery and Quoc V. Le and Ed H. Chi and Denny Zhou and Jason Wei},
    year={2022},
    eprint={2210.09261},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2210.09261},
}

@inproceedings{hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1472/",
    doi = "10.18653/v1/P19-1472",
    pages = "4791--4800",
    abstract = "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as ``A woman sits at a piano,'' a machine must select the most likely followup: ``She sets her fingers on the keys.'' With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans ({\ensuremath{>}}95{\%} accuracy), state-of-the-art models struggle ({\ensuremath{<}}48{\%}). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical `Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
}

@article{winogrande,
    author = {Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
    title = {WinoGrande: an adversarial winograd schema challenge at scale},
    year = {2021},
    issue_date = {September 2021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {64},
    number = {9},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/3474381},
    doi = {10.1145/3474381},
    abstract = {Commonsense reasoning remains a major challenge in AI, and yet, recent progresses on benchmarks may seem to suggest otherwise. In particular, the recent neural language models have reported above 90\% accuracy on the Winograd Schema Challenge (WSC), a commonsense benchmark originally designed to be unsolvable for statistical models that rely simply on word associations. This raises an important question---whether these models have truly acquired robust commonsense capabilities or they rely on spurious biases in the dataset that lead to an overestimation of the true capabilities of machine commonsense.To investigate this question, we introduce WinoGrande, a large-scale dataset of 44k problems, inspired by the original WSC, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) large-scale crowdsourcing, followed by (2) systematic bias reduction using a novel AFLITE algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. Our experiments demonstrate that state-of-the-art models achieve considerably lower accuracy (59.4\%-79.1\%) on WINOGRANDE compared to humans (94\%), confirming that the high performance on the original WSC was inflated by spurious biases in the dataset.Furthermore, we report new state-of-the-art results on five related benchmarks with emphasis on their dual implications. On the one hand, they demonstrate the effectiveness of WINOGRANDE when used as a resource for transfer learning. On the other hand, the high performance on all these benchmarks suggests the extent to which spurious biases are prevalent in all such datasets, which motivates further research on algorithmic bias reduction.},
    journal = {Commun. ACM},
    month = aug,
    pages = {99–106},
    numpages = {8},
}

@misc{Mistral_Large_Bench,
    title        = {Au Large: Announcing Mistral Large},
    author       = {{Mistral AI}},
    howpublished = {\url{https://mistral.ai/news/mistral-large}},
    year         = {2024},
    month = {2},
    day = {26},
    urldate = {2025-10-09}
}

@misc{mistral_models_benchmarks,
    title        = {Models Benchmarks},
    author       = {{Mistral AI}},
    year         = {2025},
    url          = {https://docs.mistral.ai/getting-started/models/benchmark/},
    urldate      = {2025-10-09},
}

@misc{Qwen2p5_TechReport_2025,
    title={Qwen2.5 Technical Report},
    author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    year={2025},
    eprint={2412.15115},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2412.15115},
}

@misc{MAA_AIME_2025,
    author       = "{Mathematical Association of America}",
    title        = "{MAA Invitational Competitions: American Invitational Mathematics Examination (AIME)}",
    year         = {2025},
    howpublished = {\url{https://maa.org/maa-invitational-competitions/}},
    note         = {Zugriff: 2025-10-19},
    organization = {MAA American Mathematics Competitions},
    urldate      = {2025-10-07},
}