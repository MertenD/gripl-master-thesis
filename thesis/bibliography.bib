@ONLINE{omgbpmn,
  author = {OMG},
  title = {Business Process Model and Notation (BPMN)},
  version = {2.0.2},
  year = {2013},
  month = {12},
  url = {https://www.omg.org/spec/BPMN/2.0.2/PDF},
  urldate = {2025-06-03}
}

@ONLINE{omgbpmn-xsd,
  author = {OMG},
  title = {About the Business Process Model And Notation Specification Version 2.0},
  url = {https://www.omg.org/spec/BPMN/2.0/About-BPMN},
  year = {2011},
  urldate = {2025-06-03}
}

@misc{GDPR2016,
  title = {Verordnung (EU) 2016/679 des Europäischen Parlaments und des Rates vom 27. April 2016 zum Schutz natürlicher Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr und zur Aufhebung der Richtlinie 95/46/EG (Datenschutz-Grundverordnung)},
  author = {{Europäische Union}},
  year = {2016},
  howpublished = {\url{https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32016R0679}},
}

@inproceedings{Capodieci2023BPMNEnabledDP,
  title={BPMN-Enabled Data Protection and GDPR Compliance},
  author={Antonio Capodieci and Mimma De Carolis and Stefano Lisi and Luca Mainetti and Roberto Paiano and Mariavittoria Ugirashebuja},
  booktitle={IS-EUD Workshops},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259099646},
  abstract = {The European Parliament adopted the European General Data Protection Regulation (GDPR, EU 2016/679) which revolutionized the legislative framework for personal data protection within the European Union. The GDPR mandates organizations to shift from a passive approach, relying on minimum security measures outlined in the 1994 EU Directive, to a proactive accountability-based approach. Organizations are expected to implement verification systems, foster continuous improvement, and follow principles such as privacy by design and privacy by default. The latter principle emphasizes incorporating privacy considerations throughout the entire engineering process. The challenge for organizations lies in effectively auditing their compliance with the GDPR. This study proposes a structured approach based on business process modeling to aid in GDPR compliance. It involves identifying crucial compliance points for the GDPR. A case study is presented where the method is applied to a purchase of a health insurance policy process in the context of the Secure Safe Apulia project.},
}

@article{nake2023towards,
  title={Towards identifying gdpr-critical tasks in textual business process descriptions},
  author={Nake, Leonard and Kuehnel, Stephan and Bauer, Laura and Sackmann, Stefan},
  year={2023},
  publisher={Gesellschaft f{\"u}r Informatik eV},
  url = {https://dl.gi.de/server/api/core/bitstreams/84ac5110-1a0f-4e3c-bdf8-6393555a7212/content},
  abstract = {Complying with data protection regulations is an essential duty for organizations since violating them would lead to monetary penalties from authorities. In Europe, the General Data Protection Regulation (GDPR) defines personal data and requirements for dealing with this type of data. Hence, organizations must identify business activities that deal with personal data to establish measures to fulfill these requirements. Especially for large organizations, a manual identification can be labor-intensive and error-prone. However, textual business process descriptions, such as work instructions, provide valuable insights into the data used in organizations. Therefore, we propose a first approach to automatically identify GDPR-critical tasks in textual business process descriptions. More specifically, we use a supervised machine learning algorithm to automatically identify whether a task deals with personal data or not. A first evaluation of our approach with a dataset of 37 process descriptions containing 509 activities demonstrates that our approach generates satisfactory results.},
}

@article{varela2025business,
  title={Business process models and simulation to enable GDPR compliance},
  author={Varela-Vaca, {\'A}ngel Jes{\'u}s and G{\'o}mez-L{\'o}pez, Mar{\'\i}a Teresa and Morales Zamora, Yolanda and M. Gasca, Rafael},
  journal={International Journal of Information Security},
  volume={24},
  number={1},
  pages={41},
  year={2025},
  publisher={Springer},
  url = {https://link.springer.com/article/10.1007/s10207-024-00952-7},
  abstract = {The general data protection regulation (GDPR) provides European individuals with a regulatory framework for personal data protection and privacy. Compliance with this regulation represents an essential challenge for organisations that store, transmit, and process personal data. Millionaire fines are imposed by European protection authorities due to non-compliance. Currently, non-automated solutions are applied in organisations to carry out regulatory compliance, and therefore expensive manual implementation and audits are necessary to ensure GDPR compliance. To avoid these drawbacks, this paper presents a data model and a business process model as a first step towards designing automated mechanisms for implementing the GDPR. Furthermore, the proposed models are employed to support business process simulation (BPS), which includes aspects of performance, cost, and scalability, for evaluating the resource human impact and the execution time that our proposal can have in organisations. These factors would facilitate informed decision-making by the data controller regarding the resources and the degree of GDPR compliance, supporting data controller decisions regarding determining the necessary types of resources to achieve a suitable level of compliance and to obtain the degree of GDPR compliance. Given the large number of legal articles on the GDPR and owing to space limitation herein, we focus on Articles 33 and 34 regarding notification and communication of a personal data breach.},
}

@article{ciaramella2022leveraging,
  title={Leveraging Pre-trained LLMs for GDPR Compliance in Online Privacy Policies},
  author={Ciaramella, Giovanni and Petrillo, Luca and Varilek, Margaret and Mercaldo, Francesco and Comand{\'e}, Giovanni and Martinelli, Fabio},
  year={2022},
  url = {https://ceur-ws.org/Vol-3962/paper44.pdf},
  abstract = {This article explores the use of Large Language Models (LLMs) to determine if online privacy policies comply with the General Data Protection Regulation (GDPR) since privacy policies do not always adhere to all relevant GDPR requirements. This paper proposes a method to classify privacy policies as compliant or not with a single duty within Article 13 (2)(b) of the GDPR, which mandates that data subjects be informed of their right to rectification or erasure of personal data. To address that, we employed several LLMs such as BERT-base-uncased, roBERTa-base, distilBERT-base-uncased, t5-base, and ERNIE-2.0-base-en on a dataset built by the authors from European websites domains. Moreover, once the dataset was built, a legal expert from our research team manually classified a set of privacy policies to perform the contextual sentence similarity task. As the final step, we employed a set of unseen privacy policies to test models, obtaining interesting results demonstrating moderate accuracy in identifying compliant phrases using these thresholds. Future research could include expanding the analysis to encompass other GDPR requirements and refining the models.},
}

@inproceedings{pragyan2024toward,
  title={Toward Regulatory Compliance: A few-shot Learning Approach to Extract Processing Activities},
  author={Pragyan, KC and Ghandiparsi, Rambod and Slavin, Rocky and Ghanavati, Sepideh and Breaux, Travis and Hosseini, Mitra Bokaei},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW)},
  pages={241--250},
  year={2024},
  organization={IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/10628578},
  abstract = {The widespread use of mobile applications has driven the growth of the industry, with companies relying heavily on user data for services like targeted advertising and personalized offerings. In this context, privacy regulations such as the General Data Protection Regulation (GDPR) playa crucial role. One of the GDPR requirements is the maintenance of a Record of Processing Activities (RoPA) by companies. RoPA encompasses various details, including the description of data processing activities, their purposes, types of data involved, and other relevant external entities. Small app-developing companies face challenges in meeting such compliance requirements due to resource limitations and tight timelines. To aid these developers and prevent fines, we propose a method to generate segments of RoPA from user-authored usage scenarios using large language models (LLMs). Our method employs few-shot learning with G PT-3.S Turbo to summarize usage scenarios and generate RoPA segments. We evaluate different factors that can affect few-shot learning performance consistency for our summarization task, including the number of examples in few-shot learning prompts, repetition, and order permutation of examples in the prompts. Our findings highlight the significant influence of the number of examples in prompts on summarization F1 scores, while demonstrating negligible variability in F1 scores across multiple prompt repetitions. Our prompts achieve successful summarization of processing activities with an average 70 \% ROUGE-L F1 score. Finally, we discuss avenues for improving results through manual evaluation of the generated summaries.},
}

@online{mistralai,
  author  = {Mistral AI},
  title   = {Mistral AI},
  year    = {2025},
  url     = {https://mistral.ai/},
  urldate = {2025-09-21},
}

@article{schwerin2024systematic,
  title={A systematic comparison between open-and closed-source large language models in the context of generating gdpr-compliant data categories for processing activity records},
  author={von Schwerin, Magdalena and Reichert, Manfred},
  journal={Future Internet},
  volume={16},
  number={12},
  pages={459},
  year={2024},
  publisher={MDPI},
  url = {https://www.mdpi.com/1999-5903/16/12/459},
  abstract = {This study investigates the capabilities of open-source Large Language Models (LLMs) in automating GDPR compliance documentation, specifically in generating data categories—types of personal data (e.g., names, email addresses)—for processing activity records, a document required by the General Data Protection Regulation (GDPR). By comparing four state-of-the-art open-source models with the closed-source GPT-4, we evaluate their performance using benchmarks tailored to GDPR tasks: a multiple-choice benchmark testing contextual knowledge (evaluated by accuracy and F1 score) and a generation benchmark evaluating structured data generation. In addition, we conduct four experiments using context-augmenting techniques such as few-shot prompting and Retrieval-Augmented Generation (RAG). We evaluate these on performance metrics such as latency, structure, grammar, validity, and contextual understanding. Our results show that open-source models, particularly Qwen2-7B, achieve performance comparable to GPT-4, demonstrating their potential as cost-effective and privacy-preserving alternatives. Context-augmenting techniques show mixed results, with RAG improving performance for known categories but struggling with categories not contained in the knowledge base. Open-source models excel at structured legal tasks, although challenges remain in handling ambiguous legal language and unstructured scenarios. These findings underscore the viability of open-source models for GDPR compliance, while highlighting the need for fine-tuning and improved context augmentation to address complex use cases.},
}

@inproceedings{schneid2021uncovering,
  title={Uncovering data-flow anomalies in BPMN-based process-driven applications},
  author={Schneid, Konrad and Kuchen, Herbert and Th{\"o}ne, Sebastian and Di Bernardo, Sascha},
  booktitle={Proceedings of the 36th Annual ACM Symposium on Applied Computing},
  pages={1504--1512},
  year={2021},
  url={https://dl.acm.org/doi/abs/10.1145/3412841.3442025},
  abstract = {Process-Driven Applications flourish through the interaction between an executable BPMN process model, human tasks, and external software services. All these components operate on shared process data, so it is even more important to check the correct data flow. However, data flow is in most cases not explicitly defined but hidden in model elements, form declarations, and program code. This paper elaborates on data-flow anomalies acting as indicators for potential errors and how such anomalies can be uncovered despite implicit and hidden data-flow definitions. By considering an integrated view, it goes beyond other approaches which are restricted to separate data-flow analysis of either process model or source code. The main idea is to merge call graphs representing programmed services into a control-flow representation of the process model, to label the resulting graph with associated data operations, and to detect anomalies in that labeled graph using a dedicated data-flow analysis. The applicability of the solution is demonstrated by a prototype designed for the Camunda BPM platform.},
}

@online{camunda,
  author = {Camunda Services GmbH},
  title = {Camunda Platform},
  year = {2025},
  url = {https://camunda.com/de/},
  urldate = {2025-09-22},
}

@online{bpmnio,
  author = {Camunda Services GmbH},
  title = {BPMN.io - Web-based tooling for BPMN, DMN and Forms},
  year = {2025},
  url = {https://bpmn.io/},
  urldate = {2025-09-22},
}

@misc{gdpr-guidelines-2019,
  author={{European Data Protection Board}},
  title={Guidelines 4/2019 on Article 25 Data Protection by Design and by Default},
  version = {2.0},
  year={2020},
  month = {10},
  day = {20},
  howpublished={\url{https://www.edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_201904_dataprotection_by_design_and_by_default_v2.0_en.pdf}},
}

@misc{rdg-2007,
  author={{Bundesministerium der Justiz}},
  title={Gesetz über außergerichtliche Rechtsdienstleistungen (Rechtsdienstleistungsgesetz - RDG)},
  year={2007},
  month={12},
  day={12},
  howpublished={\url{https://www.gesetze-im-internet.de/rdg/}},
  urldate={2025-08-15},
}

@online{ibm-gpt,
  title={Was ist ein GPT (Generative Pre-Trained Transformer)?},
  author={Belcic, Ivan and Stryker, Cole},
  year={2024},
  month={09},
  day={18},
  urldate={2025-09-18},
  url={https://www.ibm.com/de-de/think/topics/gpt}
}

@online{openai-models,
  author = {OpenAI},
  title = {Model Overview},
  year = {2025},
  url = {https://platform.openai.com/docs/models},
  urldate = {2025-09-18}
}

@article{vaswani2017attention,
  author={Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title={Attention Is All You Need},
  journal={CoRR},
  volume= {abs/1706.03762},
  year= {2017},
  url= {http://arxiv.org/abs/1706.03762},
  eprinttype= {arXiv},
  eprint= {1706.03762},
  timestamp= {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl= {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource= {dblp computer science bibliography, https://dblp.org},
  abstract={The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks that include an encoder and a decoder. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer,
based solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to
be superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-
to-German translation task, improving over the existing best results, including
ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,
our model establishes a new single-model state-of-the-art BLEU score of 41.8 after
training for 3.5 days on eight GPUs, a small fraction of the training costs of the
best models from the literature. We show that the Transformer generalizes well to
other tasks by applying it successfully to English constituency parsing both with
large and limited training data.},
}

@misc{minaee2025largelanguagemodelssurvey,
  title={Large Language Models: A Survey},
  author={Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
  year={2025},
  eprint={2402.06196},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.06196},
  abstract={Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022. LLMs' ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by scaling laws \cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performance of several popular LLMs on a set of representative benchmarks. Finally, we conclude the paper by discussing open challenges and future research directions. },
}

@article{liu2023prompting,
  author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  year = {2023},
  issue_date = {September 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {55},
  number = {9},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3560815},
  doi = {10.1145/3560815},
  abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website  including constantly updated survey and paperlist.},
  journal = {ACM Comput. Surv.},
  month = jan,
  articleno = {195},
  numpages = {35},
  keywords = {Pre-trained language models, prompting}
}

@inproceedings{brown2020fewshot,
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title = {Language Models are Few-Shot Learners},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  volume = {33},
  year = {2020},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic,
few-shot performance, sometimes even becoming competitive with prior state-of-
the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive
language model with 175 billion parameters, 10x more than any previous non-
sparse language model, and test its performance in the few-shot setting. For all
tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks
and few-shot demonstrations specified purely via text interaction with the model.
GPT-3 achieves strong performance on many NLP datasets, including translation,
question-answering, and cloze tasks. We also identify some datasets where GPT-
3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces
methodological issues related to training on large web corpora.},
}

@misc{openai_function_calling_2023,
  title        = {Function calling and other API updates},
  author       = {{OpenAI}},
  howpublished = {\url{https://openai.com/index/function-calling-and-other-api-updates/}},
  year         = {2023},
  urldate         = {2025-07-10}
}

@online{mistralai_structured_output,
  author  = {Mistral AI},
  title   = {Mistral AI - Structured Output},
  year    = {2025},
  url     = {https://docs.mistral.ai/capabilities/structured-output/structured_output_overview/},
  urldate = {2025-07-11}
}

@online{openai_structured_output,
  author  = {OpenAI},
  title   = {OpenAI - Structured model outputs},
  url     = {https://docs.mistral.ai/capabilities/structured-output/structured_output_overview/},
  urldate = {2025-07-11}
}

@online{openai-hello-gpt-4o,
  author  = {OpenAI},
  title   = {Hello GPT-4o},
  year    = {2024},
  month = {5},
  day = {13},
  url     = {https://openai.com/index/hello-gpt-4o/},
  urldate = {2025-07-21}

}

@article{scholak2021picard,
  author       = {Torsten Scholak and
                  Nathan Schucher and
                  Dzmitry Bahdanau},
  title        = {{PICARD:} Parsing Incrementally for Constrained Auto-Regressive Decoding
                  from Language Models},
  journal      = {CoRR},
  volume       = {abs/2109.05093},
  year         = {2021},
  url          = {https://arxiv.org/abs/2109.05093},
  eprinttype    = {arXiv},
  eprint       = {2109.05093},
  timestamp    = {Tue, 21 Sep 2021 17:46:04 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2109-05093.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code and trained models available at this https URL), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions. },
}

@misc{kalai2025languagemodelshallucinate,
  title={Why Language Models Hallucinate},
  author={Adam Tauman Kalai and Ofir Nachum and Santosh S. Vempala and Edwin Zhang},
  year={2025},
  eprint={2509.04664},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2509.04664},
  abstract = {Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such "hallucinations" persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious -- they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded -- language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This "epidemic" of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems. },
}

@article{ji2023hallucinationsurvey,
  author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  title = {Survey of Hallucination in Natural Language Generation},
  year = {2023},
  issue_date = {December 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {55},
  number = {12},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3571730},
  doi = {10.1145/3571730},
  abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
  journal = {ACM Comput. Surv.},
  month = mar,
  articleno = {248},
  numpages = {38},
  keywords = {consistency in NLG, factuality in NLG, faithfulness in NLG, extrinsic hallucination, intrinsic hallucination, Hallucination}
}

@online{deepseek,
  author  = {DeepSeek AI},
  title   = {DeepSeek AI Open Source Hugging Face Models},
  year    = {2025},
  url     = {https://huggingface.co/deepseek-ai},
  urldate = {2025-07-17}
}

@online{qwen,
  author  = {Alibaba Qwen},
  title   = {Qwen Open Source Hugging Face Models},
  year    = {2025},
  url     = {https://huggingface.co/Qwen},
  urldate = {2025-07-17}
}

@misc{hooda2024policylr,
  title={PolicyLR: A Logic Representation For Privacy Policies},
  author={Ashish Hooda and Rishabh Khandelwal and Prasad Chalasani and Kassem Fawaz and Somesh Jha},
  year={2024},
  eprint={2408.14830},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2408.14830},
  abstract = {Privacy policies are crucial in the online ecosystem, defining how services handle user data and adhere to regulations such as GDPR and CCPA. However, their complexity and frequent updates often make them difficult for stakeholders to understand and analyze. Current automated analysis methods, which utilize natural language processing, have limitations. They typically focus on individual tasks and fail to capture the full context of the policies. We propose PolicyLR, a new paradigm that offers a comprehensive machine-readable representation of privacy policies, serving as an all-in-one solution for multiple downstream tasks. PolicyLR converts privacy policies into a machine-readable format using valuations of atomic formulae, allowing for formal definitions of tasks like compliance and consistency. We have developed a compiler that transforms unstructured policy text into this format using off-the-shelf Large Language Models (LLMs). This compiler breaks down the transformation task into a two-stage translation and entailment procedure. This procedure considers the full context of the privacy policy to infer a complex formula, where each formula consists of simpler atomic formulae. The advantage of this model is that PolicyLR is interpretable by design and grounded in segments of the privacy policy. We evaluated the compiler using ToS;DR, a community-annotated privacy policy entailment dataset. Utilizing open-source LLMs, our compiler achieves precision and recall values of 0.91 and 0.88, respectively. Finally, we demonstrate the utility of PolicyLR in three privacy tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison Shopping.},
}

@inproceedings{reimers2017reporting,
  title = {Reporting Score Distributions Makes a Difference: Performance Study of {LSTM}-networks for Sequence Tagging},
  author = {Reimers, Nils  and
      Gurevych, Iryna},
  editor = {Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month = {9},
  year = {2017},
  address = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/D17-1035/},
  doi = {10.18653/v1/D17-1035},
  pages = {338--348},
  abstract = {In this paper we show that reporting a single performance score is insufficient to compare non-deterministic approaches. We demonstrate for common sequence tagging tasks that the seed value for the random number generator can result in statistically significant ($p < 10^{-4}$) differences for state-of-the-art systems. For two recent systems for NER, we observe an absolute difference of one percentage point F₁-score depending on the selected seed value, making these systems perceived either as state-of-the-art or mediocre. Instead of publishing and reporting single performance scores, we propose to compare score distributions based on multiple executions. Based on the evaluation of 50.000 LSTM-networks for five sequence tagging tasks, we present network architectures that produce both superior performance as well as are more stable with respect to the remaining hyperparameters.}
}

@misc{camunda-bpmn-model-api,
  author       = {{Camunda Services GmbH}},
  title        = {BPMN Model API},
  year         = {2025},
  howpublished = {\url{https://docs.camunda.org/manual/latest/user-guide/model-api/bpmn-model-api/}},
  urldate = {2025-06-16},
}

@misc{camunda-bpmn-model-read,
  author       = {{Camunda Services GmbH}},
  title        = {BPMN Model API — Read a Model},
  year         = {2025},
  howpublished = {\url{https://docs.camunda.org/manual/latest/user-guide/model-api/bpmn-model-api/read-a-model/}},
  urldate = {2025-06-16}
}

@online{langchain4j-ai-services,
  author  = {{Quarkiverse Contributors}},
  title   = {AI Services Reference (Quarkus LangChain4j)},
  year    = {2025},
  url     = {https://docs.quarkiverse.io/quarkus-langchain4j/dev/ai-services.html},
  urldate = {2025-06-14}
}

@online{langchain4j,
  author  = {{Langchain4j}},
  title   = {LangChain4j Documentation 2025},
  year    = {2025},
  url     = {https://docs.langchain4j.dev/},
  urldate = {2025-06-14}
}

@online{langchain4j-chat-model,
    author  = {{Langchain4j}},
    title   = {Class OpenAiChatModel.OpenAiChatModelBuilder},
    year    = {2025},
    url     = {https://javadoc.io/doc/dev.langchain4j/langchain4j-open-ai/latest/dev/langchain4j/model/openai/OpenAiChatModel.OpenAiChatModelBuilder.html},
    urldate = {2025-06-14}
}

@online{bpmn-js,
  author  = {Camunda Services GmbH},
  title   = {bpmn-js - BPMN 2.0 viewer and editor.},
  year    = {2025},
  url     = {https://bpmn.io/toolkit/bpmn-js/},
  urldate = {2025-06-20}
}

@article{blake2025datasetdiversity,
  author = {Blake, Harrison and Esther, Dorcas},
  title = {Impact of Dataset Diversity on Model Evaluation Metrics},
  year = {2025},
  month = {01},
  url = {https://www.researchgate.net/publication/387898702_Impact_of_Dataset_Diversity_on_Model_Evaluation_Metrics},
  abstract = {The evaluation of machine learning models is a critical process in understanding their performance, reliability, and generalizability. Dataset diversity, encompassing factors such as data distribution, representation of minority groups, and feature variability, plays a vital role in determining the robustness and fairness of model evaluation metrics. This paper investigates the interplay between dataset diversity and evaluation metrics, exploring how variations in dataset characteristics can influence the interpretation of model performance. Through a combination of theoretical analysis and empirical experimentation, the study aims to uncover the complexities of dataset composition and its implications for machine learning development. The findings emphasize the importance of incorporating diverse datasets in model evaluation to ensure equitable, accurate, and meaningful outcomes.},
}

@online{edpb-meta-fine,
  author  = {European Data Protection Board (EDPB)},
  title   = {1.2 billion euro fine for Facebook as a result of EDPB binding decision},
  year    = {2023},
  month = {5},
  day = {22},
  url     = {https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en},
  urldate = {2025-10-02}
}

@online{reuters-amazon-fine,
  author  = {Reuters},
  title   = {Amazon hit with record EU data privacy fine},
  year    = {2021},
  month = {7},
  day = {30},
  url     = {https://www.reuters.com/business/retail-consumer/amazon-hit-with-886-million-eu-data-privacy-fine-2021-07-30/?utm_source=chatgpt.com},
  urldate = {2025-10-02}
}

@online{datenschutzticker-amazon-fine,
  author  = {Datenschutzticker},
  title   = {Gericht bestätigt Rekordbußgeld gegen Amazon},
  year    = {2025},
  month = {4},
  day = {2},
  url     = {https://datenschutzticker.de/2025/04/gericht-bestaetigt-rekordbussgeld-gegen-amazon/},
  urldate = {2025-10-02}
}

@article{sokolova2009measureclassification,
  title={A systematic analysis of performance measures for classification tasks},
  author={Sokolova, Marina and Lapalme, Guy},
  journal={Information processing \& management},
  volume={45},
  number={4},
  pages={427--437},
  year={2009},
  publisher={Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457309000259},
  abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies.},
}

@book{manning2008ir,
  author    = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Sch{\"u}tze},
  title     = {Introduction to Information Retrieval},
  year      = {2008},
  publisher = {Cambridge University Press},
  address   = {Cambridge},
  isbn      = {9780521865715},
  url       = {https://nlp.stanford.edu/IR-book/}
}