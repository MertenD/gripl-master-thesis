\section{Verwandte Arbeiten}\label{sec:verwandte-arbeiten}

Dieses Kapitel bündelt Arbeiten zur automatisierten \emph{Klassifikation datenschutzkritischer Aktivitäten} in Geschäftsprozessen und zur \emph{Nutzung von \acp{LLM}} in Datenschutzaufgaben und Tätigkeiten im \ac{BPM}. Im Fokus stehen (1) frühe Klassifikations- und Modellierungsansätze, (2) die \ac{LLM}-\linebreak~basierte Analyse von Richtlinientexten bis hin zu strukturierter Extraktion, (3) Qualitätssicherung, Prompting und Reproduzierbarkeit sowie (4) der Einsatz von \acp{LLM} im \ac{BPM}-Lebenszyklus. Abschließend werden Forschungslücken abgeleitet.

\subsection*{Frühe Ansätze: Klassifikation und modellbasierte Kennzeichnung}

Die Identifikation von Prozessschritten mit der Verarbeitung personenbezogener Daten ist eine Voraussetzung wirksamer \ac{DSGVO}-Konformität, da nur so technische und organisatorische Maßnahmen gemäß Art.~32 Abs.~1 \ac{DSGVO} (Vertraulichkeit, Integrität, Verfügbarkeit, Belastbarkeit) zielgerichtet festgelegt werden können \cite{GDPR2016}. Nake et al.\ \cite{nake2023towards} beschreiben einen ersten automatisierten Ansatz: Mit einem überwachten Verfahren (Lernen aus gelabelten Beispielen) klassifizieren sie Aktivitäten in \emph{textuellen} Prozessbeschreibungen als \ac{DSGVO}-kritisch bzw.\ unkritisch. Der Datensatz umfasst 37 Prozesse mit 509 Aktivitäten. In der stärksten Konfiguration werden ein F1-Score von $0{,}81$ und ein Recall von $0{,}83$ erreicht. Die Generalisierbarkeit bleibt aufgrund des kleinen, nicht repräsentativen Datensatzes begrenzt. Fehler entstehen u.\,a.\ durch zu wenige Trainingsbeispiele für bestimmte Merkmalswerte. Der Ansatz ist daher als Assistenz für Datenschutzbeauftragte zu verstehen, nicht als vollständige Automatisierung.

Komplementär dazu markieren Capodieci et al.\ \cite{Capodieci2023BPMNEnabledDP} \ac{BPMN}-Elemente mit \ac{DSGVO}-Metadaten via \emph{Tagged Values} (\texttt{GDPR:legalbasis}, \texttt{GDPR:Duration}, \texttt{GDPR:\linebreak~risklevel}, \texttt{GDPR:ispersonaldataprocessing}/\texttt{GDPR:personaldata}), sodass Datenschutzaspekte bereits vor der Implementierung der Geschäftsprozesse prüfbar werden. In eine ähnliche Richtung zielt die designorientierte Arbeit von Agostinelli et al.\ \cite{agostinelli2019achievingGDPRComliance}, die \ac{DSGVO}-Anforderungen als wiederverwendbare Muster (\enquote{Datenpanne}, \enquote{Einwilligung zur Nutzung der Daten}, \enquote{Recht auf Auskunft/Berichtigung}, \enquote{Datenübertragbarkeit}, \enquote{Recht auf Vergessenwerden}) für eine transparente Einbettung in \ac{BPMN} formalisiert.

\subsection*{\acp{LLM} für Policy-Analyse}

Ciaramella et al.\ \cite{ciaramella2022leveraging} nutzen BERT, RoBERTa und DistilBERT, um Sätze aus Online-Datenschutzerklärungen gezielt im Hinblick auf die Informationspflicht aus Art.\linebreak~13~(2)(b) \ac{DSGVO} (Hinweis auf Berichtigung/Löschung) zu klassifizieren. Die Ergebnisse sind \emph{moderat} und zeigen, dass innerhalb einer Erklärung konforme und nicht konforme Passagen koexistieren. Daher schließen sie daraus, dass Konformität kein binäres Gesamteurteil auf Textebene ist.

Neuere Arbeiten gehen darüber hinaus: Hooda et al.\ \cite{hooda2024policylr} stellen mit \emph{PolicyLR} eine logikbasierte Repräsentation von Richtlinien vor und übersetzen Richtlinientexte mit einem zweistufigen \ac{LLM}-Compiler (Übersetzung $\to$ Entailment-Prüfung) in atomare Formeln. Als Evaluationsbasis dient \emph{ToS;DR} (Terms of Service; Didn’t Read), eine von der Community betriebene Plattform, auf der Freiwillige Passagen aus Nutzungs- und Datenschutzerklärungen mit prägnanten \emph{Cases} zu Datenpraktiken annotieren (z.\,B. \enquote{Sie können Ihren Inhalt von diesem Dienst löschen}). Der Compiler extrahiert solche Cases aus Richtlinientexten und prüft anschließend, ob sie logisch aus dem Text folgen (\emph{Entailment}). Mit \texttt{gemma2-27b} erreicht der PolicyLR-Compiler eine Precision von $0{,}84$ bei einem Recall von $0{,}88$. Damit werden Com-\linebreak~pliance-Checks, Konsistenzprüfungen und Vergleiche von Datenschutzerklärungen auf Basis formaler Repräsentationen möglich.

Rodriguez et al.\ \cite{rodriguez2024largelanguagemodels} optimieren Prompts, Parameter und die Kontextaufteilung\linebreak(Chunking) für die feingranulare Extraktion von Erhebungs- und Weitergabepraktiken mit \texttt{GPT-4~Turbo}. Auf MAPP erreichen sie einen F1-Score von $0{,}935$, und auf OPP-115 einen F1-Score von $0{,}93$, eine Precision von $0{,}949$, einen Recall von $0{,}912$ und eine Accuracy von $0{,}904$, während \texttt{Llama-2-70B-Chat} mit einem F1-Score von $0{,}882$ leicht darunter liegt. MAPP ist eine von Rechtsexperten manuell annotierte Sammlung aus 64 App-Datenschutzerklärungen, die die Erhebung und Weitergabe personenbezogener Daten auf Absatzebene kennzeichnen. OPP-115 umfasst 115 manuell annotierte Datenschutzerklärungen mit einem zu MAPP ähnlichen Annotationsschema und bietet damit eine breitere Domänenabdeckung.


\subsection*{Qualitätssicherung, Prompting und Reproduzierbarkeit}

Halluzinationen sind ein zentrales Problem bei \acp{LLM} für Datenschutzaufgaben und führen zu fehlerhaften Klassifikationen. Zur Reduktion von Halluzinationen koppeln Silva et al.\ \cite{silva2024entailment} einen erklärenden \ac{LLM}-Klassifikator mit einer Entailment-Prüfung. Entailment bezeichnet die Entscheidung, ob eine Aussage aus einem Text logisch folgt. Der Klassifikator liefert Label und textuelle Begründung, ein Filter prüft diese Begründung erneut, und ein Entailment-Verifikator lässt nur logisch gestützte Entscheidungen zu. Auf OPP-115 steigt der Macro-F1-Score auf $0{,}63$ (+$11{,}2$\%). Die zusätzliche Prüfstufe erhöht die Precision von $0{,}38$ auf $0{,}61$, senkt jedoch den Recall von $0{,}85$ auf $0{,}61$.

Neben der nachgelagerten Verifikation wirkt auch die Eingabe als Qualitätshebel: Von den Zero-/Few-Shot-Grundlagen \cite{brown2020fewshot,liu2023prompting} über die RoPA-Generierung \cite{pragyan2024toward} zeigen zahlreiche Arbeiten, dass Beispielanzahl, Kontextaufbereitung und Modellwahl entscheidend sind. Von Schwerin et al.\ \cite{schwerin2024systematic} zeigen im Datenschutzkontext jedoch auch, dass \acp{LLM} bereits eine sehr gute Grundperformance liefern und Few-Shot-Prompting die Qualität nur begrenzt steigert. Ein Few-Shot-Ansatz kann allerdings bei der Steuerung des Ausgabeformats helfen, ohne die Modelle neu trainieren zu müssen. Sie zeigen ebenfalls, dass kleinere, offene Modelle wie \texttt{Qwen2-7B} in bestimmten Bereichen größere proprietäre Modelle wie \texttt{GPT-4} übertreffen können.

Reimers und Gurevych \cite{reimers2017reporting} haben untersucht, wie sich die nichtdeterministische Natur von \acp{LLM} auf die Ergebnisqualität auswirkt. Sie fanden heraus, dass die Abhängigkeit vom Seed-Wert zu statistisch signifikanten Unterschieden in der Performance führen kann. Diese Varianz kann dazu führen, dass ein modernes, leistungsfähiges Modell je nach Seed von sehr gut bis mittelmäßig abschneidet. Um das in Experimenten mit \acp{LLM} zu berücksichtigen, wird vorgeschlagen, Score-Verteilungen zu vergleichen, die auf mehreren Durchläufen mit unterschiedlichen Seeds basieren. Dadurch werden die Ergebnisse robuster, und das Risiko sinkt, dass ein Modell nur aufgrund eines günstigen Seeds gut oder aufgrund eines ungünstigen Seeds schlecht abschneidet.

\subsection*{\acp{LLM} im BPM-Lebenszyklus}

Über Richtlinientexte hinaus skizzieren Vidgof et al.\ \cite{vidgof2023largelanguagemodelsbusiness} zentrale Forschungsrichtungen für \ac{LLM}-gestütztes \ac{BPM}, darunter Best Practices, \ac{BPM}-spezifische Datensätze und Leitlinien zu Prompting und Modellauswahl. Kourani et al.\ \cite{kourani2025evaluating} vergleichen in einem Benchmark mit 20 Prozessen 16 \acp{LLM} zur Transformation von Prozessbeschreibungen in ausführbare Modelle. \texttt{Claude-3.5-Sonnet} erzielt die höchste durchschnittliche Qualitätsbewertung, während z.\,B.\ \texttt{Mixtral-8x22B} zurückfällt. Es wird ein positiver Zusammenhang zwischen Fehlerbehandlung und Modellqualität beobachtet und, dass durch Output-Optimierungstechniken schwächere Modelle spürbar verbessert werden können. Für dialogorientierte Unterstützung kombinieren Bernardi et al.\ \cite{bernardi2024conversing} \ac{RAG} mit feingetunten \texttt{LLaMA-2}-Modellen (BPLLM) und erreichen bei ausreichender Kontextabdeckung präzise Antworten zu Aktivitäten und Sequenzflüssen.

\subsection*{Forschungslücken}

Aus der Literatur ergeben sich mehrere offene Fragen, die die vorliegende Arbeit adressiert:

\begin{enumerate}
    \item \textbf{Granularität und Domänenfokus.} Viele Studien fokussieren einzelne Artikel der \ac{DSGVO} (z.\,B.\ Art.~13) oder allgemeine Privacy-Tasks. Eine systematische Klassifikation \emph{kompletter} Geschäftsprozesse nach datenschutzrelevanten Aktivitäten ist selten. Zudem sind Datensätze klein und wenig repräsentativ \cite{nake2023towards}.
    \item \textbf{\ac{LLM}-Anwendung in Geschäftsprozessen.} Während es Benchmarks für Prozessmodellierung gibt, fehlen reproduzierbare Benchmarks speziell für die Klassifikation datenschutzkritischer Prozessschritte. Positionsarbeiten wie\linebreak~Vidgof et al.\ \cite{vidgof2023largelanguagemodelsbusiness} fordern \ac{BPM}-spezifische Datensätze und Modelle. Öffentlich verfügbare, auf den europäischen Rechtsraum zugeschnittene Benchmarks sind rar.
    \item \textbf{Erklärbarkeit und Halluzinationen.} \acp{LLM} erzeugen teils überzeugende, aber unzutreffende Ausgaben. Ansätze wie Silva et al.\ \cite{silva2024entailment} und Hooda et al.\ \cite{hooda2024policylr} zeigen, dass Schlussfolgerungsprüfer oder formale Repräsentationen nötig sind, um Halluzinationen zu reduzieren.
    \item \textbf{Datenschutz- und Sicherheitsbedenken.} Studien nutzen häufig geschlossene Modelle wie \texttt{GPT-4}, deren Einsatz aufgrund möglicher Datenübermittlungen in die USA datenschutzrechtlich problematisch sein kann. Offene Modelle wie \texttt{Qwen2-7B} liefern vergleichbare Ergebnisse \cite{schwerin2024systematic} und sind für \ac{EU}-Organisationen potenziell vorteilhaft.
    \item \textbf{Prompt-Engineering-Leitlinien.} Obwohl mehrere Arbeiten den maßgeblichen Einfluss von Prompt-Gestaltung (z.\,B.\ Beispielanzahl, Kontexttrennung) belegen \cite{liu2023prompting,pragyan2024toward}, fehlen breit akzeptierte Leitfäden speziell für Datenschutz- und \ac{BPM}-Kontexte.
\end{enumerate}

Diese Lücken unterstreichen den Bedarf an umfassenden, reproduzierbaren Benchmarks sowie an robusten Methoden zur Klassifikation datenschutzkritischer Aktivitäten in Geschäftsprozessen unter Berücksichtigung der europäischen \ac{DSGVO}. Das folgende Kapitel präzisiert die Problemdefinition und die Qualitätsziele der vorliegenden Arbeit.
