\section{Verwandte Arbeiten}\label{sec:verwandte-arbeiten}

Dieses Kapitel bündelt Arbeiten zur automatisierten \emph{Klassifikation datenschutzkritischer Aktivitäten} in Geschäftsprozessen und zur \emph{Nutzung von \acp{LLM}} in Datenschutzaufgaben und Tätigkeiten im \ac{BPM}. Im Fokus stehen (i) frühe Klassifikations- und Modellierungsansätze, (ii) \ac{LLM}-basierte Analyse von Richtlinientexten bis hin zu strukturierter Extraktion, (iii) Qualitätssicherung, Prompting und Reproduzierbarkeit sowie (iv) der Einsatz von \acp{LLM} im \ac{BPM}-Lebenszyklus. Abschließend werden Forschungslücken abgeleitet.

\subsection*{Frühe Ansätze: Klassifikation und modellbasierte Kennzeichnung}

Die Identifikation von Prozessschritten mit Verarbeitung personenbezogener Daten ist Voraussetzung wirksamer \ac{DSGVO}-Konformität, da nur so technische und organisatorische Maßnahmen gemäß Art.~32 Abs.~1 (Vertraulichkeit, Integrität, Verfügbarkeit, Belastbarkeit) zielgerichtet festgelegt werden können \cite{GDPR2016}. Nake et al.\ \cite{nake2023towards} beschreiben einen ersten automatisierten Ansatz: Mit einem überwachten Verfahren (Lernen aus gelabelten Beispielen) klassifizieren sie Aktivitäten in \emph{textuellen} Prozessbeschreibungen als \ac{DSGVO}-kritisch vs.\ unkritisch. Der Datensatz umfasst 37 Prozesse mit 509 Aktivitäten. In der stärksten Konfiguration werden ein F1-Score von $0{,}81$ und ein Recall von $0{,}83$ erreicht. Die Generalisierbarkeit bleibt aufgrund des kleinen, nicht repräsentativen Datensatzes begrenzt. Fehler entstehen u.\,a.\ durch zu wenige Trainingsbeispiele für bestimmte Merkmalswerte. Der Ansatz ist daher als Assistenz für Datenschutzbeauftragte zu verstehen, nicht als vollständige Automatisierung.

Komplementär markieren Capodieci et al.\ \cite{Capodieci2023BPMNEnabledDP} \ac{BPMN}-Elemente mit \ac{DSGVO}-\linebreak~Metadaten via \emph{Tagged Values} (\texttt{GDPR:legalbasis}, \texttt{GDPR:Duration},\linebreak~\texttt{GDPR:risklevel}, \texttt{GDPR:ispersonaldataprocessing}/\texttt{GDPR:personaldata}),\linebreak~sodass Datenschutzaspekte bereits in der Pre-Implementation-Phase prüfbar werden. In eine ähnliche Richtung zielt die designorientierte Arbeit von Agostinelli et al.\ \cite{agostinelli2019achievingGDPRComliance}, die \ac{DSGVO}-Anforderungen als wiederverwendbare Muster (\enquote{Data Breach}, \enquote{Consent to Use the Data}, \enquote{Right to Access/Rectify}, \enquote{Portability}, \enquote{Right to be Forgotten}) für eine transparente Einbettung in \ac{BPMN} formalisiert.

\subsection*{\acp{LLM} für Policy-Analyse}

Ciaramella et al.\ \cite{ciaramella2022leveraging} nutzen BERT, RoBERTa und DistilBERT, um Sätze aus Online-Datenschutzerklärungen gezielt im Hinblick auf die Informationspflicht aus Art.~13 (2)(b) \ac{DSGVO} (Hinweis auf Berichtigung/Löschung) zu klassifizieren. Die Ergebnisse sind \emph{moderat} und zeigen, dass innerhalb einer Erklärung konforme und nicht konforme Passagen koexistieren. Daher schließen sie daraus, dass Konformität kein binäres Gesamteurteil nur auf Textebene ist.

Neuere Arbeiten gehen darüber hinaus: Hooda et al.\ \cite{hooda2024policylr} führen mit \emph{PolicyLR} eine logikbasierte Form für Richtlinien ein und übersetzen Texte mit einem zweistufigen \ac{LLM}-Compiler (Übersetzen $\to$ Entailment-Prüfung) in atomare Formeln. Auf ToS;DR (annotierte Nutzungsbedingungen) erzielen Open-Source-\acp{LLM} wie \texttt{gemma2-27b} eine Precision von $0{,}91$ und $0{,}88$ Recall. Damit werden Compliance-Checks, Konsistenzprüfungen und Policy-Vergleiche möglich. Rodriguez et al.\ \cite{rodriguez2024largelanguagemodels} optimieren Prompts, Parameter und die Kontextaufteilung (Chunking) für die feingranulare Extraktion von Erhebungs- und Weitergabepraktiken mit \texttt{GPT-4~Turbo}. Auf MAPP erreichen sie $0{,}935$ F1-Score, auf OPP-115 $0{,}93$ F1-Score, $0{,}949$ Precision, $0{,}912$ Recall und $0{,}904$ Accuracy, während \texttt{Llama-2-70B-Chat} mit $0{,}882$ F1 leicht darunter liegt.

\subsection*{Qualitätssicherung, Prompting und Reproduzierbarkeit}

Zur Reduktion von Halluzinationen koppeln Silva et al.\ \cite{silva2024entailment} einen erklärenden \ac{LLM}-Klassifikator mit einem Entailment-Prüfer, der nur Entscheidungen passieren lässt, die sich aus dem Text folgern lassen. Auf OPP-115 steigt der Macro-F1-Score auf $0{,}63$ (plus $11{,}2$\%). Die zusätzliche Prüfstufe erhöht die Präzision von $0{,}38$ auf $0{,}61$, senkt aber den Recall von $0{,}85$ auf $0{,}61$. Für Screening-Aufgaben mit nachgelagerter menschlicher Prüfung eignet sich der Entailment-Schritt damit eher als optionaler High-Precision-Filter. Prompting wirkt als weiterer Qualitätshebel: Von Zero-/Few-Shot-Grundlagen \cite{brown2020fewshot,liu2023prompting} über RoPA-Generierung \cite{pragyan2024toward} bis zu domänenspezifischen Kategorien \cite{schwerin2024systematic} zeigt sich, dass Beispielanzahl, Kontextaufbereitung und Modellwahl entscheidend sind. Reimers und Gurevych \cite{reimers2017reporting} empfehlen zudem, aufgrund seed-bedingter Varianz Score-Verteilungen statt Einzelwerte zu berichten.

\subsection*{\acp{LLM} im BPM-Lebenszyklus}

Über Richtlinientexte hinaus skizzieren Vidgof et al.\ \cite{vidgof2023largelanguagemodelsbusiness} zentrale Forschungsrichtungen für \ac{LLM}-gestütztes \ac{BPM}, darunter Best Practices, \ac{BPM}-spezifische Datensätze und Leitlinien zu Prompting und Modellauswahl. Kourani et al.\ \cite{kourani2025evaluating} vergleichen in einem Benchmark mit 20 Prozessen 16 \acp{LLM} zur Transformation von Prozessbeschreibungen in ausführbare Modelle. \texttt{Claude-3.5-Sonnet} erzielt die höchste durchschnittliche Qualitätsbewertung, während z.\,B.\ \texttt{Mixtral-8x22B} zurückfällt. Es wird ein positiver Zusammenhang zwischen Fehlerbehandlung und Modellqualität wird beobachtet und dass durch Output-Optimierungstechniken schwächere Modelle spürbar verbessert werden können. Für dialogorientierte Unterstützung kombinieren Bernardi et al.\ \cite{bernardi2024conversing} \ac{RAG} mit feingetunten \texttt{LLaMA-2}-Modellen (BPLLM) und erreichen bei ausreichender Kontextabdeckung präzise Antworten zu Aktivitäten und Sequenzflüssen.

\subsection*{Forschungslücken}

Aus der Literatur ergeben sich mehrere offene Fragen, die die vorliegende Arbeit adressiert:

\begin{enumerate}
    \item \textbf{Granularität und Domänenfokus.} Viele Studien fokussieren einzelne Artikel (z.\,B.\ Art.~13) oder allgemeine Privacy-Tasks. Eine systematische Klassifikation \emph{kompletter} Geschäftsprozesse nach datenschutzrelevanten Aktivitäten ist selten. Zudem sind Datensätze klein und wenig repräsentativ \cite{nake2023towards}.
    \item \textbf{\ac{LLM}-Anwendung in Geschäftsprozessen.} Während es Benchmarks für Prozessmodellierung gibt, fehlen reproduzierbare Benchmarks speziell für die Klassifikation datenschutzkritischer Prozessschritte. Positionsarbeiten wie\linebreak~Vidgof et al.\ \cite{vidgof2023largelanguagemodelsbusiness} fordern \ac{BPM}-spezifische Datensätze und Modelle. Öffentlich verfügbare, auf den europäischen Rechtsraum zugeschnittene Benchmarks sind rar.
    \item \textbf{Erklärbarkeit und Halluzinationen.} \acp{LLM} erzeugen teils überzeugende, aber unzutreffende Ausgaben. Ansätze wie Silva et al.\ \cite{silva2024entailment} und Hooda et al.\ \cite{hooda2024policylr} zeigen, dass Schlussfolgerungsprüfer oder formale Repräsentationen nötig sind, um Halluzinationen zu reduzieren.
    \item \textbf{Datenschutz- und Sicherheitsbedenken.} Studien nutzen häufig geschlossene Modelle wie \texttt{GPT-4}, deren Einsatz aufgrund möglicher Datenübermittlungen in die USA datenschutzrechtlich problematisch sein kann. Offene Modelle wie \texttt{Qwen2-7B} liefern vergleichbare Ergebnisse \cite{schwerin2024systematic} und sind für \ac{EU}-Organisationen potenziell vorteilhaft.
    \item \textbf{Prompt-Engineering-Leitlinien.} Obwohl mehrere Arbeiten den maßgeblichen Einfluss von Prompt-Gestaltung (z.\,B.\ Beispielanzahl, Kontexttrennung) belegen \cite{pragyan2024toward,liu2023prompting}, fehlen breit akzeptierte Leitfäden speziell für Datenschutz- und \ac{BPM}-Kontexte.
\end{enumerate}

Diese Lücken unterstreichen den Bedarf an umfassenden, reproduzierbaren Benchmarks sowie an robusten Methoden zur Klassifikation datenschutzkritischer Aktivitäten in Geschäftsprozessen unter Berücksichtigung der europäischen \ac{DSGVO}. Das folgende Kapitel präzisiert die Problemdefinition und die Qualitätsziele der vorliegenden Arbeit.
