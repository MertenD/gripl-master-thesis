\section{Problemstellung}\label{sec:problemstellung}

\begin{itemize}
    \item Trotz der genannten Potenziale fehlt es bisher an standardisierten, reproduzierbaren Vergleichen verschiedener Modelle für die konkrete Aufgabe Aktivitäten in Geschäftsprozessen nach \enquote{kritisch} und \enquote{unkritisch} zu klassifizieren. Erste Ansätze, wie z.B. der von Nake et al. \cite{nake2023towards}, zeigen dass maschinelles Lernen grundsätzlich in der Lage ist \ac{DSGVO}-kritische Aktivitäten in textuellen Prozessbeschreibungen zu erkennen, jedoch existieren keine einheitlichen Benchmarks für einen systematischen Vergleich unterschiedlicher LLMs.
    \item Auch von Schwerin und Reichert \cite{schwerin2024systematic} heben hervor, dass trotz großer Fortschritte im Einsatz von \acp{LLM} für juristische Aufgaben bislang erhebliche Lücken in der Evaluation für compliance-spezifische Anwendungen bestehen und geeignete \ac{DSGVO}-spezifische Benchmarks fehlen.
    \item Besonders interessant ist die Frage, wie sich Open-Source-Modelle - insbesondere mit Ursprung aus der \ac{EU} - im Vergleich zu internationalen außerhalb der \ac{EU} entwickelten Modellen schlagen und welche Trade-offs dabei entstehen \cite{schwerin2024systematic}.
    \item TODO Eine zusätzliche Herausforderung ergibt sich aus der Natur von \ac{BPMN}-Modellen: Typischerweise konzentrieren sie sich auf den Kontrollfluss und vernachlässigen die Datenebene. Datenobjekte werden oftmals gar nicht explizit modelliert oder nur implizit in den Aktivitäten referenziert. Dadurch ist die Datennutzung von Aktivitäten nicht direkt erkennbar und muss aus textuellen Beschreibungen und dem Kontext erschlossen werden \cite{schneid2021uncovering}. Das erschwert dies die automatische Identifikation von \ac{DSGVO}-kritischen Aktivitäten, da Algorithmen personenbezogene Datenflüsse zunächst indirekt und über den Kontext ableiten müssen.
\end{itemize}