\section{Kriterien}\label{sec:kriterien}

Dieser Abschnitt legt die Auswahlkriterien der \acp{LLM} offen, nach denen die Modelle ausgewählt und kategorisiert wurden. Tabelle \ref{tab:kriterien} zeigt eine Übersicht der Kriterien. Diese Kriterien helfen, die Modelle systematisch zu vergleichen und ihre Eignung für die Klassifizierungsaufgabe zu bewerten.

\begin{table}[htbp]
    \centering
    \caption{Übersicht der Kriterien zur Modellauswahl}
    \label{tab:kriterien}
    \begin{tabularx}{\textwidth}{p{0.3\textwidth} p{0.65\textwidth}}
        \toprule
        \textbf{Kriterium} & \textbf{Beschreibung} \\
        \midrule
        Herkunft & Das Land in dem das Modell entwickelt wurde bzw. der Hauptsitz des Anbieters \\
        Lizenz & Art der Lizenz, wie bspw. Open-Source oder proprietär \\
        Größe & Anzahl der Parameter in Milliarden (B) \\
        Kontext & Maximale Anzahl der Token, die das Modell verarbeiten kann \\
        Letztes Update & Datum der letzten Aktualisierung des Modells bei Hugging Face \cite{huggingface} \\
        Downloads & Anzahl der Downloads des Modells bei Hugging Face, sofern verfügbar \\
        \bottomrule
    \end{tabularx}
\end{table}

Ein wesentliches Auswahlkriterium ist die geografische \textbf{Herkunft} der Modelle. Als \emph{\ac{EU}-Modell} gelten Modelle, deren Anbieter ihren Hauptsitz in der \ac{EU} haben, deren Veröffentlichung in der \ac{EU} erfolgt oder die schwerpunktmäßig in der \ac{EU} entwickelt oder verfeinert wurden. Alle anderen Modelle werden als \emph{international} eingeordnet. Diese Unterscheidung ist relevant, da europäische Modelle sowohl beim Training als auch beim Betrieb stärker den europäischen Datenschutzbestimmungen unterliegen und somit potenziell besser für den Einsatz in datensensiblen Bereichen wie der Klassifizierung von \ac{BPMN}-Modellen geeignet sind. Zudem ist die \ac{DSGVO} eine unmittelbar geltende \ac{EU}-Verordnung und prägt dadurch die regulatorischen Anforderungen an Entwicklung und Betrieb besonders stark.

Ein weiteres zentrales Kriterium ist die \textbf{Lizenzierung} der Modelle. Als \emph{Open-Source} veröffentlichte Modelle im Sinne der \emph{Open Source Definition} der \ac{OSI} erlauben Nutzung, Studium, Veränderung und Weiterverbreitung unter einer konformen Lizenz \cite{OSI_OSD}. Davon zu unterscheiden sind \emph{Open-Weights}-Modelle: Hier sind die Gewichte zwar öffentlich beziehbar, wodurch Modelle bspw. selbst betrieben werden können, die zugehörige Lizenz kann jedoch restriktive Klauseln enthalten (z.\,B. Nutzungs- oder Output-Beschränkungen). Daher gelten sie rechtlich nicht als \ac{OSI}-Open-Source (ein Beispiel ist die Meta-Llama\,3 Community Lizenz \cite{Llama3_License}). In dieser Arbeit gilt ein Modell als \emph{offen} bzw.\ \emph{Open-Source-nah}, wenn

\begin{enumerate}
    \item die Gewichte frei zugänglich sind und
    \item eine \emph{permissive} Lizenz (z.\,B. Apache-2.0 oder MIT) eine breite kommerzielle Nutzung erlaubt (z.\,B. Mistral 7B \cite{HF_Mistral7B_2025}, GPT-OSS \cite{OpenAI_GPTOSS_ModelCard_2025, OpenAI_GPTOSS_Blog_2025} oder DeepSeek V3.1 \cite{HF_DeepSeek_V3_1_2025}).
\end{enumerate}

Modelle mit \emph{Community}- oder \emph{Eigennutzer}-Lizenzen (z.\,B. Mistral Large Instruct unter Mistral Research License \cite{HF_MistralLargeInstruct_2025, MRL_Research_License}) werden rechtlich \emph{nicht} als \ac{OSI}‑Open‑Source gewertet, können aber technisch als Vergleich herangezogen werden.

Die \textbf{Modellgröße} wird in \emph{Anzahl der Parameter} angegeben. Meist in \emph{Milliarden} (Billionen, engl. \emph{Billion}) Parametern (B, engl. \emph{Billion}). 1\,B = \(10^9\) Parameter. Diese Zahl korreliert mit dem Ressourcenbedarf für Training und Inferenz sowie der Leistungsfähigkeit \cite{webdev-llm-sizes}. Für die Einordnung werden hier folgende Klassen verwendet:

\begin{itemize}
    \item \textbf{Klein} (\(\leq\)\,\textasciitilde{}25\,B Parameter): z.\,B. Mistral\,7B Instruct (\textasciitilde{}7.3\,B) \cite{HF_Mistral7B_2025}.
    \item \textbf{Groß} (\(>\)\,\textasciitilde{}25\,B Parameter): z.\,B. GPT‑OSS\,120B (\textasciitilde{}117\,B) \cite{OpenAI_GPTOSS_ModelCard_2025}.
\end{itemize}

Die Klassifikation dient als methodische Abgrenzung für die Experimente. Kleinere Modelle lassen sich häufig lokal ausführen, größere erfordern typischerweise mehrere GPUs. Parameterzahl ist dabei ein nützlicher, wenn auch unvollständiger Indikator für Ressourcenbedarf und erwartete Leistung. Dies ermöglicht konsistente Entscheidungen zu Deployment und Kosten.

Der \textbf{Kontext} gibt an, wie viele Token ein Modell gleichzeitig verarbeiten kann. Ein Token ist dabei eine Grundeinheit von Text, die ein Wort, einen Teil eines Wortes oder sogar ein einzelnes Zeichen darstellen kann. Die Größe des Kontextfensters beeinflusst maßgeblich, wie gut ein Modell längere Texte verstehen und darauf reagieren kann \cite{ibm-llm-context}.

Neben den genannten Hauptkriterien werden weitere Merkmale erfasst, um die Modelle umfassend zu charakterisieren. Dazu gehören das \textbf{letzte Update} des Modells, um einordnen zu können, wie aktuell das Modell ist, und wie viele \textbf{Downloads} das Modell hat, sofern verfügbar. Diese Informationen helfen, die Popularität und Akzeptanz der Modelle in der Community einzuschätzen.

Im nächsten Abschnitt werden auf Basis dieser Kriterien die ausgewählten Modelle vorgestellt.