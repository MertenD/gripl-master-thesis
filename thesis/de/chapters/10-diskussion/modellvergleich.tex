\section{Modelle im Vergleich}\label{sec:modelle-im-vergleich}

Hinsichtlich der Herkunft sind einzelne europäische Modelle wettbewerbsfähig. Dazu gehören das proprietäre \texttt{Mistral Medium 3.1} mit F1-Score $= 0{,}843$, Recall $0{,}877$ und Precision $0{,}811$ sowie das Open-Source-Modell \texttt{Mistral-Large-\linebreak~Instruct-2411} mit F1-Score $= 0{,}823$ und Recall $= 0{,}872$. Im Durchschnitt liegen jedoch internationale Modelle vorne und zeigen eine geringere Varianz und höhere Robustheit. Daraus folgt, dass die Auswahl des Modells nicht allein auf die Herkunft gestützt werden sollte, sondern eine ganzheitliche Bewertung der Leistungsfähigkeit, Stabilität und Transparenz beim Training und Betrieb erfolgen muss.

Beim Vergleich \emph{Open-Source vs.\ proprietär} übertreffen mehrere offene Modelle die proprietären Vertreter in F1-Score und Recall. \texttt{GPT-4o} überzeugt zwar durch eine sehr hohe Precision von $0{,}892$, verfehlt aber das Recall-Mindestziel. \texttt{Mistral Medium 3.1} bietet einen ausgewogenen Kompromiss und erfüllt alle Zielwerte, liegt aber hinter den besten Open-Source-Modellen. Für Recall-priorisierte Vorscreenings sind \texttt{Qwen3-235B-A22B-Thinking-2507}, \texttt{GPT-OSS-20B} und\linebreak\texttt{DeepSeek-R1-Distill-Qwen-14B} die stärksten Kandidaten. Diese Ergebnisse unterstreichen, dass Open-Source-Modelle in spezialisierten Aufgaben konkurrenzfähig und proprietäre Lösungen nicht zwangsläufig überlegen sind.

Mit Blick auf die \emph{Modellgröße} liegen kleine ($\leq 25B$) und große Modelle ($> 25B$) im Mittel nahe beieinander. Kleine Modelle wie \texttt{GPT-OSS-20B} halten bei deutlich größeren Modellen mit oder übertreffen sie sogar. Zudem sind sie durch geringe Hardware-Anforderungen gut für On-Premises-Betrieb geeignet, was in datenschutzsensiblen Kontexten und im Hinblick auf Kosten von Vorteil ist. Die reine Parameteranzahl erweist sich damit nicht als hinreichendes Kriterium für die Modellauswahl. Vielmehr sind die Trainingsdaten, Feinabstimmung und Architektur der Modelle für ihre Leistung entscheidend. Für die Praxis bedeutet das: Die Modellauswahl sollte entlang der Zielmetrik (Recall-Priorität), dem erwarteten nachfolgenden Prüfungsaufwand (Precision) und den betrieblichen Rahmenbedingungen (Kosten, Hosting) erfolgen. Besonders wenn personenbezogene Daten verarbeitet werden, sind \ac{EU}-Hosting und On-Premises-Betrieb wichtige Kriterien, die durch kleinere, leistungsfähige Modelle erleichtert werden.