\chapter{Versuchsaufbau}\label{ch:versuchsaufbau}

Hier kann ich auch erwähnen, dass ich aufgrund von Hardware Limitierungen Openrouter benutze, um auch auch größere Modelle zu testen. Ich wollte in meinen Ergebnissen nicht durch fehlende Hardware limitiert sein.

\begin{itemize}
    \item Die Modelle werden jeweils mit dem gleichen Klassifizierungsalgorithmus und den gleichen Datensätzen benutzt.
    \item Jedes Experiment wird jeweils mit jedem vorhandenen Testdatensatz durchgeführt (Uni, reale größere Prozesse, kleine Prozesse)
    \item Ein Experiment besteht aus einer Menge von Modellen, die jeweils 5 mal mit dem gleichen Datensatz evaluiert werden. Der Seed ist dabei bei jeder Wiederholung ein anderer. Der Seed für eine Wiederholung wird auf Basis des Seeds in der Konfigurationsdatei und der Wiederholungsnummer generiert, sodass die Ergebnisse reproduzierbar sind.
    \item Es werden verschiedene LLM-Modelle vergleichen
    \item Es werden vom gleichen LLM-Modell/Anbieter die unterschiedlichen Größen verglichen
    \item Ein Testcase gilt als korrekt klassifiziert, wenn genau die als kritisch gelabelten Aktivitäten als kritisch klassifiziert worden sind. Sobald es False Positives oder False Negatives gibt, ist ein Testcase nicht korrekt klassifiziert worden
\end{itemize}

In Abbildung \ref{lst:mistral-experiment-config} ist ein Beispiel für eine Konfigurationsdatei eines Experiments mit Mistral Modellen dargestellt. In diesem Experiment werden vier verschiedene Mistral Modelle miteinander verglichen. Die drei Datensätze (Uni, reale größere Prozesse, kleine Prozesse) haben die IDs 2, 7 und 1. Es werden jeweils 5 Wiederholungen mit einem Seed von 24523833 durchgeführt.

Es wird außerdem Openrouter als API-Anbieter genutzt, um auch die größeren Modelle von Mistral testen zu können. Openrouter bietet eine einfache Möglichkeit, verschiedene Modelle über eine einheitliche API anzusprechen. Dies ist besonders hilfreich, da ich so nicht durch meine eigene Hardware limitiert bin und auch größere Modelle testen kann. Der API-Schlüssel wird über eine Umgebungsvariable eingebunden, um die Konfigurationsdatei nicht mit sensiblen Daten zu versehen und sie so auch in einem öffentlichen Repository speichern zu können. Alle weiteren Konfigurationsdateien der durchgeführten Experimente sind im Anhang unter \ref{lst:gemma-experiment-config, lst:deepseek-experiment-config, lst:qwen-experiment-config, lst:gpt-oss-experiment-config} zu finden. Außerdem gibt es alle genutzten Datensätze, Konfigurationen und die daraus resultierenden Ergebnisse auch im GitLab Repository zu finden\footnote{\url{LINK_TO_GITLAB_REPOSITORY}}.

In einem Experiment werden die Modelle eines Anbieters miteinander verglichen. Die Ergebnisse der Experimente können jedoch ohne Probleme miteinander verglichen werden, da der Klassifizierungsalgorithmus und die Datensätze immer die gleichen sind. So können beispielsweise die Mistral Modelle mit den Gemma Modellen verglichen werden, obwohl sie in unterschiedlichen Experimenten getestet wurden. Die Aufteilung in verschiedene Experimente dient lediglich der Übersichtlichkeit in der Benutzeroberfläche des Evaluationsframeworks.

\begin{lstlisting}[caption={Konfigurationsdatei des Experiments mit Mistral Modellen}, label={lst:mistral-experiment-config}]
defaultEvaluationEndpoint: /gdpr/analysis/prompt-engineering
seed: 24523833
maxConcurrent: 10
repetitions: 5
models:
  - label: Mistral-7B-Instruct-v0.3
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-7b-instruct-v0.3
      apiKey: ${OPEN_ROUTER_API_KEY}
  - label: Mistral-8x7B-Instruct-v0.1
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mixtral-8x7b-instruct
      apiKey: ${OPEN_ROUTER_API_KEY}
  - label: Mistral-Large-Instruct-2411
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-large-2411
      apiKey: ${OPEN_ROUTER_API_KEY}
  - label: Mistral Medium 3.1
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-medium-3.1
      apiKey: ${OPEN_ROUTER_API_KEY}
datasets:
  - 2
  - 7
  - 1
\end{lstlisting}
