\section{Konfigurationen}\label{sec:konfigurationen}

Die Konfigurationen der Experimente sind im YAML-Format in Listings \ref{lst:mistral-experiment-config}, \ref{lst:gemma-experiment-config}, \ref{lst:deepseek-experiment-config}, \ref{lst:qwen-experiment-config} und \ref{lst:gpt-experiment-config} dargestellt. Sie enthalten die zu evaluierenden Modelle, die zu verwendenden Datensätze, den Basis-Seed sowie die Anzahl der Wiederholungen und weitere Rahmenparameter. In Listing \ref{lst:mistral-experiment-config} wird ein Experiment dargestellt, in dem vier verschiedene Mistral-Modelle über OpenRouter evaluiert werden. Die Datensätze werden jeweils fünf Mal durchlaufen. Der Basis-Seed ist auf \texttt{24523833} gesetzt.

\begin{lstlisting}[caption={Konfigurationsdatei des Experiments mit Mistral Modellen}, label={lst:mistral-experiment-config}]
defaultEvaluationEndpoint: /gdpr/analysis/prompt-engineering
seed: 24523833
maxConcurrent: 10
repetitions: 5
models:
  - label: Mistral-7B-Instruct-v0.3
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-7b-instruct-v0.3
      apiKey: ${OPEN_ROUTER_API_KEY}
      temperature: 0.1
      topP: 1
  - label: Mistral-8x7B-Instruct-v0.1
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mixtral-8x7b-instruct
      apiKey: ${OPEN_ROUTER_API_KEY}
      temperature: 0.1
      topP: 1
  - label: Mistral-Large-Instruct-2411
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-large-2411
      apiKey: ${OPEN_ROUTER_API_KEY}
      temperature: 0.1
      topP: 1
  - label: Mistral Medium 3.1
    llmProps:
      baseUrl: https://openrouter.ai/api/v1
      modelName: mistralai/mistral-medium-3.1
      apiKey: ${OPEN_ROUTER_API_KEY}
      temperature: 0.1
      topP: 1
datasets:
  - 2
  - 7
  - 1
\end{lstlisting}

Auf Basis des Seeds aus der Konfiguration und der aktuellen Wiederholungsnummer wird in dem Evaluationsframework für jede Wiederholung deterministisch ein neuer Seed generiert. Dadurch sind die Ergebnisse reproduzierbar und dennoch wird die Stabilität der Modelle über mehrere Wiederholungen mit unterschiedlichen Seeds abgebildet.

Alle Datensätze, Konfigurationen und die daraus resultierenden
Ergebnisse sind außerdem im GitLab‑Repository verfügbar\footnote{Siehe das GitLab Repository: \hyperlink{https://gitlab.com/andreaskonrad/bpmn-gdpr-llm-evaluation}{// TODO}}.

Um bei der Zero‑Shot‑Klassifikation deterministische und formatkonsistente Ergebnisse zu erzielen, wurden die Inferenz‑Hyperparameter \texttt{temperature} und \texttt{topP} bewusst konservativ gewählt. Der Parameter \texttt{temperature} steuert die Zufälligkeit der Modellausgabe: niedrige Werte priorisieren die wahrscheinlichsten Tokens und machen die Ausgabe deterministischer. Für Aufgaben, die faktische Genauigkeit und Präzision erfordern, empfehlen aktuelle Arbeiten daher sehr niedrige Temperaturen; höhere Werte (z.\,B.\ \texttt{temperature}=0{,}8 oder 2) verschlechtern hingegen die Klassifikationsleistung und führen zu nicht‑reproduzierbaren Ausgaben \cite{renze2024effect,mu2024navigating}.
In dieser Arbeit wird daher konsequent \texttt{temperature}=0{,}1 verwendet. Dieser Wert reduziert Zufallseffekte erheblich, ohne den Output zu stark einzuschränken, und entspricht den Empfehlungen vergleichbarer Studien zur Zero‑Shot‑Klassifikation \cite{mu2024navigating}.

Der Parameter \texttt{topP} legt fest, bis zu welcher kumulierten Wahrscheinlichkeit Tokens für die nächste Auswahl herangezogen werden. Durch die Wahl \texttt{topP}=1 werden keine Tokens vorab ausgeschlossen, sodass alle möglichen Tokens des Vokabulars berücksichtigt werden und allein die \texttt{temperature} den Grad der Stochastik bestimmt \cite{renze2024effect}. In Kombination mit einer sehr niedrigen \texttt{temperature} ermöglicht \texttt{topP}=1 einen fokussierten und weitgehend deterministischen Output bei gleichzeitig maximalem Stichprobenraum \cite{mu2024navigating}.

%Die theoretisch noch deterministischere Einstellung \texttt{temperature}=0 (Greedy Decoding) wurde vermieden, da neuere Untersuchungen hier Instabilitäten und leichte Varianz in der Ausgabe beobachten \cite{atil2024nondeterminism}.
%Die Kombination aus \texttt{temperature}=0{,}1 und \texttt{topP}=1 stellt somit einen robusten Kompromiss zwischen Reproduzierbarkeit und Stabilität dar und wird in allen Experimenten genutzt.